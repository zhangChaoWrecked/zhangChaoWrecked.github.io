<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java 执行Linux Command]]></title>
    <url>%2F2020%2F05%2F21%2FJava%20%E6%89%A7%E8%A1%8CLinux%20Command%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 import org.springframework.util.StringUtils;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RestController;import java.io.BufferedInputStream;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;@RestControllerpublic class ExecuteController &#123; /** * 执行指定命令 */ @RequestMapping(value = &quot;/executeMult&quot;, method = RequestMethod.GET) public Object executeMult(String command) throws IOException &#123; if (StringUtils.isEmpty(command)) return &quot;Error Command &quot;; String[] strings = new String[3]; strings[0] = &quot;/bin/sh&quot;; strings[1] = &quot;-c&quot;; strings[2] = command; StringBuffer stringBuffer = new StringBuffer(); int exitValue = -1; BufferedReader bufferedReader = null; try &#123; // command process Process process = Runtime.getRuntime().exec(strings); BufferedInputStream bufferedInputStream = new BufferedInputStream(process.getInputStream()); bufferedReader = new BufferedReader(new InputStreamReader(bufferedInputStream)); // command log String line; while ((line = bufferedReader.readLine()) != null) &#123; stringBuffer.append(line); stringBuffer.append(System.getProperty(&quot;line.separator&quot;)); System.out.println(line); &#125; // command exit process.waitFor(); exitValue = process.exitValue(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (bufferedReader != null) &#123; bufferedReader.close(); &#125; &#125; if (exitValue == 0) &#123; return stringBuffer.toString(); &#125; else &#123; return &quot;command exit value(&quot; + exitValue + &quot;) is failed&quot;; &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速查询日志命令]]></title>
    <url>%2F2020%2F05%2F20%2F%E5%BF%AB%E9%80%9F%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[./tail.sh filename linenumber seratchText123456789101112131415161718192021222324252627282930313233#字体颜色blue_font=&quot;\E[34m\033[01m&quot;green_font=&quot;\033[1;32m&quot;yellow_font=&quot;\033[33m&quot;light_green_font_withbackcolor=&quot;\033[42;30m\033[01m&quot;light_green_font=&quot;\033[32m\033[01m&quot;red_font=&quot;\033[1;31m&quot;color_end=&quot;\033[0m&quot;#参数校验if [ ! -n &quot;$1&quot; ] ;then echo -e &quot;$&#123;blue_font&#125; 请指定日志文件目录 ! $&#123;color_end&#125;&quot; exit 1; fi line=$2 if [ ! -n &quot;$2&quot; ] ;then line=20 fi if [ ! -n &quot;$3&quot; ] ;then echo -e &quot;$&#123;yellow_font&#125; 执行:tail -&quot;$line&quot;f $1 $&#123;color_end&#125;&quot; tail -&quot;$line&quot;f $1 else echo -e &quot;$&#123;yellow_font&#125; 执行:tail -&quot;$line&quot;f $1 |grep &quot;$3&quot; $&#123;color_end&#125;&quot; tail -&quot;$line&quot;f $1 |grep &quot;$3&quot; fi]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式案例]]></title>
    <url>%2F2019%2F12%2F18%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[替换文本格式的数据为 hashmap.put(“a1”,”b1”);1234567a1 b1 23g sdfs正则表达式：([A-Z0-9]+)[ ]+(.*) hashmap.put(&quot;$1&quot;,&quot;$2&quot;)]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>正则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门文档]]></title>
    <url>%2F2019%2F12%2F18%2FDocker%E5%85%A5%E9%97%A8%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[1Docker是一个开源的应用容器引擎。Docker可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的Linux机器上，也可以实现虚拟化。容器是完全使用沙箱机制相互之间不会有任何接口（类似 iPhone的app）,更重要的是容器性能开销极低。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756 本内容整理来源于《微服务架构基础 Spring Boot+Spring Cloud+Docker.pdf》 下载地址在 http://www.86clouds.com/detail/383366928 ####【Docker安装】 #####更新apt索引包$ apt-get update #使用Docker库$ apt-get install apt-transport-https ca-certificates curl software-properties-common#添加Docker官网的GPG key$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | apt-key add - #添加Docker稳定的仓库源(根据Ubuntu镜像版本的不同进行选择安装)amd64：$ add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;armhf：$ add-apt-repository &quot;deb [arch=armhf] https://download.docker.com/linux/ubuntu $ (lsb___release -cs) stable&quot;s390x:$ add-apt-repository &quot;deb [arch=s390x] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;2.安装 DockerCE设置好Docker仓库之后，就可以从存储库中安装和更新Docker,其实现步骤如下。(1 )更新apt的索引包。$ apt-get update(2)安装不同版本的Docker。在安装Docker时，通常会根据个人情况选择安装不同的版 本。为此，Docker提供了两种安装方式，一是安装默认的最新版本的Docker,二是安装指定版 本的Docker,具体如下。・安装最新版本的Docker,具体指令如下。$ apt-get install docker-ce需要注意的是，执行上述指令后，之前存在的任何版本的Docker都会被替换。安装指定版本的Docker,具体指令如下。$ apt-get install docker-ce=&lt;VERSION&gt;从上述指令可以看出，安装指定版本的Docker时，需要通过“=”将版本字符串附加到安 装包后。为了更好地选择指定版本的Docker,可以使用apt-cache madison指令查看Docker仓库 中的Docker版本信息，具体指令如下。$ apt-cache madison docker-ce docker-ce | 5:19.03.3~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 5:19.03.2~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 5:19.03.1~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 5:19.03.0~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 5:18.09.9~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 5:18.09.8~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 5:18.09.7~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 5:18.09.6~3-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages ................................................................................................................执行上述指令后，就会显示出当前Docker仓库提供的在线的Docker的版本信息，其中第二列是版本字符串，第三列是存储库名称，用于指示安装包来自哪个存储库。(3)安装完成后，可以使用 docker run hello-world指令运行测试，具体指令如下。$ docker run hello-world在没有网络或者网络条件较差的情况下，我们可以选择离线安装Docker (使用DEB格式的 安装文件)。这种安装方式的好处是不依赖于网络，但其缺点是后期使用时需要手动升级和维护, 并且每次升级时都需要下载一个新的.deb文件。离线安装方式的具体实现步骤如下。1.下载离线安装文件通过官方提供的地址 https://download.docker.com/linux/ubuntu/dists/,下载安装 Docker的.debUbuntu Xenial 16.04 ( LTS )版本，所以要单击图中的xenial链接并进入到pool/stable/目录下，然后根据情况选择amd64、armhf或者s390x版本的.deb文件2.使用离线文件安装Docker通过下载的.deb文件进行Docker离线安装非常简单，只需要在Ubuntu系统的终端中执行 如下指令。$ dpkg -i /path/to/package.deb需要注意的是，使用sudo dpkg -i指令安装Docker时，一定要指定读者下载的.deb文件 所在地址，例如上面指令表示执行/path/to/路径下的package.deb文件。(4) docker version 查看 docker版本 Client: Docker Engine - Community Version: 19.03.3 API version: 1.40 Go version: go1.12.10 Git commit: a872fc2 Built: Tue Oct 8 00:59:54 2019 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 19.03.3 API version: 1.40 (minimum version 1.12) Go version: go1.12.10 Git commit: a872fc2 Built: Tue Oct 8 00:58:28 2019 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.2.10 GitCommit: b34a5c8af56e510852c35414db4c1f4fa6172339 runc: Version: 1.0.0-rc8+dev GitCommit: 3e425f80a8c931f88e6d94a8c831b9d5aa481657 docker-init: Version: 0.18.0 GitCommit: fec3683 ############【Docker基本的使用介绍】################ $ 编写Dockerfile文件$ docker build -t hellodocker . -t参数指定了生成的镜像名称为 hellodocker 指令最后的点[•]代表的是当前目录下的应用上下文 如果Dockerfile不在则需要替换为Dockerfile的路径地址$ docker images 查看镜像$ docker run -d -p 5000:80 hellodocker 访问程序，查看结果。使用宿主机的浏览器通过地址http://localhost:5000来访问容器中运行的程序 创建并启动容器,镜像就类似一个Java类，必须有具体的实例才能使用 docker run是Docker创建并启动容器的指令,-d参数表示在后台运行容器, -p参数将容器暴露的80端口映射到宿主机的 5000 端口 $ docker ps 查看Docker运行中的容器效果$ docker stop 653347ecc6df 停止容器############【Dockerfile基本的介绍】################指令 说明FROM 指定基础镜像MAINTAINER 指定镜像维护者信息RUN 用于执行指定脚本命令CMD 指定启动容器时执行的命令EXPOSE 指定容器暴露的端口ENV 指定环境变量ADD 将文件从宿主机复制到容器指定位置，同时对压缩文件有自动解压功能COPY 将文件从宿主机复制到容器指定位置ENTRYPOINT 设置容器启动时需要运行的命令WORKDIR 为后续的如RUN、CMD、ENTRYPOINT, COPY、ADD指定工作目录############【Docker常用操作指令】################docker images 列岀镜像docker search 搜索镜像docker pull 拉取镜像docker build 构建镜像docker rmi 删除镜像docker run 创建并启动容器docker ps 列岀容器docker exec 执行容器docker stop 停止容器docker start 启动容器docker rm 删除容器 $ docker images 执行上述指令后，系统会将所有本地镜像都展示出来 REPOSITORY 镜像名称 TAG 镜像的参数，类似于版本号，默认是latestoIMAGE ID 镜像ID,是唯一值。此处看到的是一个长度为12的字符串，实际上它是64 位完整镜像ID的缩写形式CREATED 距今创建镜像的时间SIZE 镜像大小 $ docker search ubuntu 执行上述指令后，系统终端就会将搜索到的有关Ubuntu的镜像展示出来 NAME 表示镜像的名称，这里有两种格式的名称，其中不带有&quot;/”的表示官方镜像，而带有7&quot;的表示其他用户的公开镜像。公开镜像&quot;/”前面是用户在±的用户名(后面是对应的镜像DESCRIPTION 表示镜像的描述，这里只显示了一小部分。STARS 表示该镜像的收藏数，用户可以在Docker Hub ±对镜像进行收藏，一般可以通 过该数字反映出该镜像的受欢迎程度。OFFICIAL： 表示是否为官方镜像。AUTOMATED 表示是否自动构建镜像。例如，用户可以将自己的Docker Hub绑定到如 Github上，当代码提交更新后，可以自动构建镜像。 $ docker pull ubuntu Docker会自动从Docker Hub上下载最新版本的Ubuntu到本地 $ docker pull ubuntu:14.04 拉取指定版本的镜像到本地 $ cd workspace/dockerspace/ 在Dockerfile文件所在目录构建镜像 $ docker build -t hellodocker2 . 进入Dockerfile文件所在目录后，可以使用docker build指令进行镜像构建 $ cd ~ 在其他目录构建镜像$ docker build -t hellodocker3 /home/shitou/workspace/dockerspace/.$ docker rmi -f hellodocker2 hellodocker3 当本地存放过多不需要的镜像时$ docker run -d -p 5000:80 --name test hellodocker 创建并启动容器$ docker ps 列出容器CONTAINER ID 表示生成的容器ID。IMAGE 表示生成该容器的镜像名称。COMMAND 表示启动容器时运行的命令，Docker要求在启动容器时必须运行一个命令。CREATED 表示容器创建的时间。STATUS 表示容器运行状态，例如Up表示运行中，Exited表示已停止。PORTS 表示容器内部暴露的端口映射到主机的端口。NAMES 表小生成容器的名称,由Docker引擎自动生成，可以像上述不例中使用—name 参数指定生成容器的名称。$ docker stop f0c9a8b6e8c5 停止容器$ docker ps -a 查看该容器$ docker start f0c9a8b6e8c5 启动容器$ docker restart f0c9a8b6e8c5 重启容器############【Docke管理指令】################docker container 用于管理容器docker image 用于管理镜像docker network 用于管理Docker网络docker node 用于管理Swarm集群节点docker plugin 用于管理插件docker secret 用于管理Docker机密docker service 用于管理Docke一些服务docker stack 用于管理Docker堆栈docker swarm 用于管理Swa「mdocker system 用于管理Docke「docker volume 用于管理数据卷############【 Docker Hub远程镜像管理】################1.登录 Docker Hub 要使用Docker Hub就需要先在其官网https://hub.docker.com/注册一个账号(需要用户名、 邮箱和密码)，通过邮件认证后，即可登录到Docker Hub中心Docker Hub的仓库分为Public (公开)和Private (私有)两种，公开仓库 可以被其他开发者查看和拉取资源；而私有仓库不对外公开，只对内部创建组织的成员公开。Docker Hub为免费用户只提供了一个私有仓库，如果需要使用更多的私有仓库，则可以单击上 图中的“Get more”链接通过付费的方式进行获取。其他功能 1.镜像管理：可以从社区或官方搜索、拉取、管理、推送镜像等。 2.自动构建镜像：Docker Hub支持连接到源代码仓库，如GitHub和Bitbucket,当源代码 进行修改后可以进行自动化构建镜像。 3.Webhooks (监测工具)：属于自动构建的一个特性，Webhooks能够让开发者成功推送仓 库后触发一些行为。Organizations (组织)：可以创建工作组，来协同开发、管理一个镜像仓库。 4.GitHub和Bitbucket集成：支持集成代码仓库GitHub和Bitbucket到工作流中。2.修改镜像名称$ docker tag hellodocker:latest itheima/hellodocker:latest 修改镜像名称3.登录认证$ docker login 4.推送镜像$ docker push itheima/hellodocker:latest 如果想要将推送的镜像仓库设置为私有的，有两种方式：一种方式就是推送完成后立即进入 Docker Hub仓库面板，进入对应仓库详情中的Settings菜单/功能下，单击“Make Private”按钮设 置为私有仓库；另一种方式就是在推送镜像之前，先在Docker Hub上通过Create Repository (创建 仓库)链接创建一个私有仓库，然后再以该私有仓库为名重命名一个本地镜像，推送到该指定私有仓库上。 相比Docker Hub而言，Docker Registry的功能就不够全面了，且需要自己手动配置、升 级、维护和管理，所以说对于Docker镜像管理不太熟悉的人员推荐使用Docker Hubo如果开 发者想要严格控制镜像存储位置，完全拥有自己的镜像分配渠道，或者要想将镜像存储和分布紧 密嵌入到自己开发的程序中，贝U选择Docker Registry更适合。接下来，本小节将针对Docker Registry本地私有镜像仓库的管理进行详细讲解。 ############【 Docker网络管理】################$ docker network ls Docker中默认的三种网络分别为bridge.host和none,其中名为bridge 的网络就是默认的bridge驱动网络，也是容器创建时默认的网络管理方式，配置后可以与宿主 机通信从而实现与互联网通信功能，而host和none属于无网络，容器添加到这两个网络时不能 与外界网络通信。############【 Docker数据管理】################(1)Docker数据存储机制 使用Docker时，我们操作的都是镜像和由镜像生成的容器，所以想要更好地了解Docker 内部的数据存储机制，就必须从镜像、容器与数据存储的关系出发。Docker镜像是通过读取Dockerfile文件中的指令构建的，Dockerfile中的每条指令都会创 建一个镜像层，并且每层都是只读的，这一系列的镜像层就构成了 Docker镜像(2)Docker数据存储方式 在默认情况下，Docker中的数据都是存放在容器层的，但是这样存储数据却有较多的缺陷， 具体表现如下。当容器不再运行时，容器中的数据无法持久化保存，如果另一个进程需要这些数据，那么 将很难从容器中获取数据。容器层与正在运行的主机紧密耦合，不能轻易地移动数据。容器层需要一个存储驱动程序来管理文件系统，存储驱动程序提供了一个使用Linux内核 的联合文件系统，这种额外的抽象化降低了性能。 基于上述种种原因，多数情况下Docker数据管理都不会直接将数据写入容器层，而是使用 另一种叫做Docker volume数据外部挂载的机制进行数据管理。针对Docker volume数据外部挂载机制，Docker提供了三种不同的方式将数据从容器映射 到Docker宿主机，它们分别为：volumes(数据卷)、bind mounts(绑定挂载)和tmpfs mounts (tmpfs挂载).这三种数据管理方式的具体选择，需要结合实际情况进行考虑，其中的volumes 数据卷是最常用也是官方推荐的数据管理方式。无论选择使用哪种数据管理方式，数据在容器内看起来都一样的，而在容器外则会被被挂载 到文件系统中的某个目录或文件中。(3)数据管理方式volumes 存储在主机文件系统中(在Linux系统 下是存在于/var/lib/Docker/volumes/目录),并由 Docker 管理，非Docker进程无法修改文件系统的这个部分。bind mounts 可以存储在主机系统的任意位置，甚至可能是重要的系统文件或目录，在 Docker主机或容器上的非Docker进程可以对它们进行任意修改。tmpfs mounts 只存储在主机系统的内存中，并没有写入到主机的文件系统中。==========================================================================================================================================================############【 Docker Compose】################ Docker Compose,俗称Docker编排工具，是用来定义和运行多容器应用的Docker工具。 通过该编排工具，可以使用yml文件来配置应用程序服务，然后只需要一条简单的服 务部署指令就可以从配置中创建并启动所有服务 对于简单的个别服务应用可以使用Dockerfile构建镜像，然后使用docker run或者 docker service create命令启动容器服务；对于多容器服务如微服务架构项目,最好使用 Docker Compose编排工具进行统一管理。1.安装 (1)安装条件 Docker Compose是依赖于Docker引擎的，所以在安装Docker Compose之前要确保机 器上已经安装了 Docker (可以使用docker -v指令查看)。 (2)安装 Compose 使用curl命令从GitHub的Compose仓库拉取Docker Compose,具体操作指令如下。 $ sudo curl -L https://github.com/docker/compose/releases/download/1.16.1/ docker-compose-&apos;uname -s&apos;-&apos;uname -m&apos; -o /usr/local/bin/docker-compose 执行上述指令后，就会从GitHub下载并安装Docker Compose工具，该过程需要耗时几分 钟。从上述指令也可以看出，指定下载的Docker Compose版本为1.16.1 读可以根据实际情况选择下载对应的版本，各个版本的信息可参考地址https://github.com/docker/compose/releases 查看。 $ sudo chmod +x /usr/local/bin/docker-compose 更改Docker Compose的可执行文件权限 $ docker-compose --version 查看安装的Docker Compose效果及版本，具体操作指令如下。 (3)卸载 Compose $ rm /usr/local/bin/docker-compose 2.Compose file文件的使用说明(1)编写Dockerfile文件。使用Dockerfile定义应用程序的环境，这样可以在任何地方使用它，Dockerfile的作用就是为每个服务构建镜像。(2)定义yml文件(通常是docker-compose.yml )就是将前面介绍的服务部署指令及相 关参数都统一在该文件中编写和配置，这样就省去了针对不同服务各自运行的麻烦。(3)运行服务部署指令。根据具体的部署需求，来执行相应的部署指令，Docker会读取 docker-compose.yml文件内容启动整个应用服务。 在上述三步中，第一步中Dockerfile文件的编写已经在第7章有过讲解，而第三步的服务部 署指令会在后面服务部署环节进行说明，所以现在需要掌握的就是如何编写docker-compose.yml文件。接下来，将针对Compose file文件的定义和配置进行详细讲解。 https://docs.docker.eom/compose/compose-file 配置文档地址 【docker-compose.yml】version: * 3 *services: web: image: id/imagename:lablerestart: on-failurecontainer_name: my-web-containerports: - 8080:8080networks: - example-netdepends_on: - dbdeploy: replicas: 2 restart__policy: condition: on-failuredb: image: mysql:5.6 restart: on-failure container_name: my-mysql-container ports: - 3306:3306 volumes: - example-mysql:/var/lib/mysql networks: - example-net environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: mysql_database deploy: replicas: 1 restart__policy: condition: on-failure placement: constraints: [node.role == manager]networks: example-net:volumes: example-mysql:总体来看： version &quot;3&apos;&apos;表示文件是使用3版本的约束进行编写的。 services 下面包含有web和db两个服务配置项，每一个服务配置项都有镜像image、 端口 ports.网络networks和部署deploy等配置信息，同时web服务配置依赖于db服务配置。 networks (网络)和volumes (数据卷)：在服务部署时会自动创建example-net网络和 example-mysql 数据卷。结合上述示例进行整体介绍后，相信大家已经对Compose file文件的配置和样式已经有了 一个初步的了解。下面将对Compose file文件中一些常用的配置进行更详细的解释，具体说明 如下。1.version (版本)version通常在一个docker-compose.yml文件的最顶部，用来表示文件内容的约束版本(类似于XML文件约束),本书编写时的最新版本为3.3版本。2.services (服务)services用来声明服务，在services下的所有同缩进的应用名称都代表一个服务，如上面 示例中的web和db。在进行多服务部署的时候，有多少个服务需要同时部署，就需要在services 参数下面声明并配置多少个服务。3.image (镜像)所有启动的服务都是依赖镜像构建的，所以每一个服务下面首先要声明依赖的镜像名称，- 般都是xxx/xxx:lable的形式。如果是本地私有仓库镜像，一般为IP:PORT/xxx：lable (如果省略 了 lable标签，则默认是latest)的形式。4.restart (重启策略)restart 表示服务重启策略，在使用Compose file文件启动所有服务过程中，有些服务由于 个别原因可能会启动失败。为了保证服务正常启动，需要使用该参数来确保服务重启(在集群环 境下该属性会被忽略)。restart服务重启策略可以设为四个值，分别如下。 restart: &quot;no&quot; #服安默认值为n。，即服务失败后没有任何动作 restart: always #表示服务会一直重新启动 restart: on-failure #表示服务提示失败错误后会重新启动 restart: unless-stopped #表示只有服务柱停止后才会重启5.container_name (容器名称)container_name表示单个服务启动后的容器名称。在3版本以后，如果是在集群多实例环 境下部署，该参数就会被忽略。6.ports (端口)ports用于指定服务向外暴露的端口。Compose支持多种形式的ports端口映射，在上面示 例中使用了比较常规的端口映射方式(宿主机端口：容器端口)来暴露服务。7.networks (网络)networks用于配置服务网络。在前面介绍Docker时，已经介绍过在进行服务部署时最好使 用自定义网络，这里就可以使用networks参数。上面示例中指定了各个服务启动后的网络管理 为example-net,该网络会在服务启动时自动创建。8.depends_on (服务依赖)depends.on表示多个服务之间的依赖关系，用来确定服务启动的先后顺序。针对该参数， 需要特别注意以下两点。depends.on决定了服务的依赖关系，如示例中的web依赖db,所以db服务会先于web 服务启动，但并不表示db服务完全启动成功后才启动web服务，它只决定启动的先后顺序而已。在3版本中，depends_on参数将会被忽略。9.links (服务关联)links表示多个服务之间的相互访问关系，即可以通过服务名称或别名来访问关联的服务； 同时也具有depends.on参数一样的服务依赖关系，即可以确定服务启动的先后顺序。针对该参 数，也需要注意以下几点。同depends_on —样，links确定了服务的依赖关系，但它只决定服务启动的先后顺序而已。如果同时定义了 links和networks参数，使用links连接的服务必须有一个共同的网络。在3版本中，links参数也将会被忽略。10.deploy (服务集群部署)deploy参数是Docker Compose针对Swarm集群部署提供的(在非集群环境下该参数及其 子参数会被忽略)。该参数及其子参数专门用于指定与服务部署和运行相关的配置，并且该参数 只有在3版本以及部署到Swarm集群时才会生效。11.replicas (服务实例副本)replicas表示服务实例的副本数量。在Swarm集群环境下，为了实现服务器端的负载均衡, 通常会将一个服务实例复制多个副本运行，如上述实例中的web服务就提供了 2个副本。12.restart_policy (重启策略)restart_policy参数同前面介绍的restart类似，都是用来配置服务重启策略的，只是该属性 配置在deploy参数下，并只在集群环境下生效。该参数包含多个子属性及属性值，具体示例 如下。 restart_policy:&apos; . condition: on-failure #表示服务重启的条件，值有 none、on-failure 和 any delay: 5s #表示重启服务之间等待时间，默认为0 max_attempts : 3 #表示失败后尝试重启的次数 window: 120s #表示等待多久来确定服务是否启动成功13.placement (位置约束)placement用来配置指定位置的约束，当服务在Swarm集群环境下部署时会随机分配到管 理节点和其他工作节点上。在上述示例中由于将mysql数据挂载到了本机example-mysql数据 卷中，所以使用了 placement的子参数constraints:[node.role == manager]指定该服务只在 manager管理节点上运行。14.volumes (数据卷)volumes表示数据卷，就是将容器中的数据备份到宿主机地址(具体可回顾前面章节介绍的 数据管理)□上述示例中是将mysql数据挂载到本地example-mysql数据卷中，如果该数据卷 不存在，服务启动时也会默认创建。15.environment (环境变量)environment用于配置服务启动时需要的环境变量，如上述示例中MYSQL_ROOT_ PASSWORD表示数据库root用户的密码，MYSQL_DATABASE表示数据库启动后自动创建的数据库。==========================================================================================================================================================############【 微服务与Docker】################1.[添加Dockerfile文件] 在Docker中，应用都是部署在容器中的，而容器又由镜像生成，镜像则通常是通过Dockerfile 文件构建的，所以微服务与Docker整合的第一步就是要提供Dockerfile文件。第9章讲解整合时编写的微服务项目microservice-mallmanagement主要有4个子项目模 块（包括2个微服务模块和2个辅助服务模块），我们需要针对每一个子项目模块编写对应的 Dockerfile文件。这里以用户订单管理微服务模块为例，所编写的Dockerfile文件的具体内容如: FROM java:8-jre MAINTAINER shirx 〈shirx@qq.com&gt; ADD ./target/microservice-userservice-0.0.1-SNAPSHOT.jar \ /app/microservice-userservice.jar CMD [&quot;java&quot;, H-Xmx200mn, &quot;-jar&quot;, &quot;/app/microservice-userservice.jar&quot;] EXPOSE 8030具体说明如下：1~2行设置了一个基础镜像java:8-jre来提供项目的运行环境，并通过MAINTAINER配 置了该镜像的维护者信息。3~4行通过ADD命令将生成的项目jar包（在target目录下）复制到容器内部的app目 录下，并重命名为 microservice-userservice.jar。第5行通过CMD命令指定了由该镜像生成的容器的启动命令（其实就是java -jar microservice-userservice.jar 启动 jar 包的命令）o第6行通过EXPOSE指令指定容器暴露的端口号为8030 跟项目配置文件application, yml中指定的端口相同。将上述Dockerfile文件直接放在项目的根目录即可,其他服务编写的Dockerfile文件与文件基本相同，只需要将Dockerfile中的项目名称和版本号后缀，以及复制到容器内部的JAR包名称进行相应修改即可。2.[添加 dockerfile-maven 插件] Dockerfile文件编写完成后，就可以使用Docker的相关指令构建镜像并运行容器，然后访 问容器中的应用了。只是上述所有的操作都是手动完成的，如果需要部署多个服务，将会非常麻烦。针对这种情况,MAVEN提供了一个dockerfile-maven-plugin插件,很好地支持了与Docker 的整合。该插件的使用非常简单，只需要在所有需要生成Docker容器项目的pom文件中添加该插件&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupld&gt;com.spotify&lt;/groupld&gt; &lt;artifactld&gt;dockerfile-maven-plugin&lt;/artifactld&gt; &lt;version&gt;l.3.6&lt;/version&gt; &lt;configuration&gt; &lt;!--生成的镜像名称--&gt; &lt;repository&gt; $&#123;docker.image.prefix&#125;/$&#123;project.artifactld&#125; &lt;/repository&gt; &lt;!―生成的镜像版本--&gt; &lt;tag&gt;$&#123;project.version&#125;&lt;/tag&gt; &lt;!--推送到私有镜像仓库或者DockerHub时需要开启用户认证--&gt; &lt;useMavenSettingsForAuth&gt;true&lt;/useMavenSettingsForAuth&gt; &lt;/configuration&gt; &lt;!--直接使用mvn install命令打包项目，就会自动构建并推送镜像--&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default&lt;/id&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;&lt;properties&gt;&lt;!- 配置镜像前缀（就是仓库服务地址）--&gt;〈docker.image.prefix&gt;l92.168.197.143:5000&lt;/docker.image.prefix&gt;&lt;/properties&gt; 通过&lt;plugin&gt;标签添加了一个版本为136的dockerfile-maven-plugin插件。分别使用&lt;repository&gt;和&lt;tag&gt;标签配置了生成的镜像名称和标签。其中$&#123;docker. image.prefix&#125;用于指定镜像前缀（需要继续配置）,$&#123;project.artifactld&#125;用于将项目名称指定为镜 像名称；$&#123;project.version）用于将项目版本指定为镜像版本。使用&lt;useMavenSettingsForAuth&gt;标签开启仓库用户认证。生成的镜像不管是推送到 DockerHub,还是本地私有镜像仓库，都必须先登录认证并通过后才可推送。该标签的作用就是 在使用maven插件的时候开启用户认证（本地未创建认证的私有仓库或者后续手动推送镜像则 不需要配置此标签）在&lt;execution&gt;标签中分别使用&lt;phase&gt;和&lt;goals&gt;子标签配置了 mvn的执行命令和自动 化动作。其中上述配置表示在使用mvn install执行打包项目时，会先进行打包，然后自动执行 镜像构建和镜像推送任务，这种配置方式可以很好地完成项目与Docker的自动化整合工作（如 果想要手动构建和推送镜像则可以去除&lt;executions&gt;标签）。在&lt;properties&gt;标签中使用&lt; docker.image.prefix&gt;子标签配置了生成的镜像前缀（也就是本地私有仓库地址）,来为$&#123;docker.image.prefix&#125;赋值。上述配置文件指定了＜docker.image.prefix＞标签（即镜像仓库前缀）,这里使用的地址 192.168.197.143:5000 就是第 8 章介绍 Docker Swarm 集群时搭建的 Docker 机器 managerl 中的私有仓库地址，后续项目将在该集群上进行部署。上述 dockerfile-maven-plugin 插件的配置，需要在 microservice-mallmanagement 项目 的4个子项目模块的pom文件中分别添加，并且无需任何更改。3.[添加 docker-compose.yml 编排文件]version: &quot;3&quot;services: mysql: image: mysql:5.6 restart: on-failure ports: - 3306:3306 volumes: - microservice-mysql:/var/lib/mysql networks: - microservice-net environment: MYSQL__ROOT_PASSWORD: root MYSQL_DATABASE: microservice__mallmanagement deploy: replicas: 1 restart_policy: condition: on-failure placement: constraints: [node.role == manager] eureka-server: image: 192.168.197.143:5000/microservice-eureka-server:0.0.1-SNAPSHOT restart: on-failure ports: - 8761:8761 networks: - microservice-net deploy: replicas: 1 restart_policy: condition: on-failure gateway-zuul: image: 192.168.197.143:5000/microservice-gateway-zuul:0.0.1-SNAPSHOT restart: on-failure ports: -8050:8050 networks: -microservice-net depends_on: -eureka-server deploy: replicas: 1 restart_policy: condition: on-failure placement: constraints: [node.role == manager] order-service: image: 192.168.197.143:5000/microservice-orderservice:0.0.1-SNAPSHOT restart: on-failure ports: -7900:7900 networks: -microservice-net depends_on: -mysql -eureka-server deploy: replicas: 2 restart_policy: condition: on-failure user-service: image: 192.168.197.143:5000/microservice-userservice:0.0.1-SNAPSHOT restart: on-failure ports: -8030:8030 networks: -microservice-net depends_on: -mysql -eureka-server deploy: replicas: 2 restart_policy: condition: on-failure visualizer: image: dockersamples/visualizer:stable ports: -8081:8080 networks: -microservice-net volumes: -/var/run/docker.sock:/var/run/docker.socknetworks: microservice-net:volumes: microservice-mysql: 在文件中，提供了 6个启动服务，除包含了 microservice-mallmanagement项目自带的 eureka-server、gateway-zuuk order-service 和 user-service 4个子项目外，还包含了 mysql数据库服务和visualizer集群环境下可视化工具服务。这些服务都是通过networks配置了 —个指定的名称为microservice-net的自定义网络（服务部署时会自动创建该网络），服务之间 可以通过该网络实现通信。需要注意的是，构建服务的镜像名称要与微服务整合时生成的镜像名称一致，否则无法找到 ,微服务项目与Docker的整合配置就已经完成，剩下的就是如何将项目进行打包，并 通过Docker进行部署了 4.[环境搭建以及镜像准备]1.搭建Docker主机 要将微服务项目运行在Docker中，首先必须保证运行环境安装了Docker引擎，这里我们就选用前面第8章中的8.2小节搭建的名为manage&quot;的Docker机器，作为本次微服务部署的主机，同时也是集群环境下的管理节点，而另两台名为worked和worker2的Docker机器仍作 为集群环境下的工作节点（在实际开发中，Docker Swarm集群可能会涉及更多的工作节点，并 且会设置多个管理节点） 需要说明的是，此次演示为了方便查看和管理，在managerl服务主机上搭建了本地私有镜像仓库，其仓库服务地址为192.168.197.143:5000,这与前面项目配置和整合文件编写的镜像前缀地址都是一致的，否则无法推送到指定仓库。关于本地私有仓库的搭建，此处不再做详细说 明，具体内容可以参考第7章中7.4.4小节介绍的Docker Registry本地私有仓库配置。2.安装应用编译工具JDK (1)下载Linux版本的JDK工具包，本书使用的是jdk-8u144-linux-x64.tar.gz版本，并 在Linux机器上使用tar命令进行解压，具体操作指令如下。$ sudo tar -zxvf jdk-8ul44-linux-x64.tar,gz (2)将执行上述解压指令后产生的解压包移动到自定义目录下（这里将解压包直接移动到了 /usr/lib/jvm @录下，如果不存在，要先创建该目录），具体操作指令如下。$ sudo mv jdkl.8.0 144/ /usr/lib/jvm (3)配置JDK环境变量。修改/etc/profile文件，在profile文件中添加以下配置(注意JDK 解压包名称和版本号) #set java environment export JAVA_H0ME=/usr/lib/jvm/jdkl.8.0_144/ export JRE_HOME=$&#123;JAVA_HOME&#125;/j re export CLASSPATH=.:$&#123;JAVA_HOME&#125;/1ib:$&#123;JRE_HOME)/1ib export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH 完成有关JDK的环境配置后，可以执行source/etc/profile指令使配置立即生效。我们可以 使用java -version命令查看安装后的效果。3.安装应用打包工具Maven 在前面介绍微服务与Docker整合配置时就已经说明，此次整合部署是通过Maven的install 命令自动执行打包、镜像构建和推送的，所以在此必须先要安装并配置好Maveno其具体配置 过程如下。(1)下载Linux版本的Maven工具包，本书使用的是apache-maven-3.5.0-bin.tar.gz版 本，并在Linux机器上使用tar命令进行解压，具体操作指令如下：$ sudo tar -zxvf apache-maven-3.5.0-bin.tar.gz(2)将执行上述解压命令后产生的解压包移动到自定义目录下(这里将解压包直接移动到了 opt目录下)，具体操作指令如下：$ sudo mv apache-maven-3.5.0/ /opt(3)配置Maven环境变量。修改/etc/profile文件，在profile文件中添加以下配置(注意 Maven解压包名称和版本号)： #set maven envirment export M2_HOME=/opt/apache-maven-3.5.0/ export M2=$M2_HOME/bin export MAVEN_OPTS=n-Xms2 5 6m -Xmx512mn export PATH=$M2:$PATH 完成有关Maven的环境配置后，同样可以执行source /etc/profile指令使配置立即生效，然 后通过mvn -v命令查看安装配置后的Maven信息4.镜像准备 由于之前10.2小节中dockerfile-maven的配置，在完成打包后也会自动构建镜像并推送到指定仓库，但无论是推送到DockerHub还是本地私有镜像仓库，必须先登录认证才可进行推送。所以为了能够自动打包、构建镜像和推送镜，在使用mvn install命令打包之前，除了需要预 先在dockerfile-maven插件配置中配置&lt;useMavenSettingsForAuth&gt;标签属性值为true外，还 需要在Maven的settings.xml配置文件（参考上一小节基础环境搭建时Maven的安装位置，此 示例中的地址为/opt/apache-maven-3.5.0/conf/settings.xml）中配置服务认证信息，具体配置 内容如下（注意要配置在&lt;servers&gt;标签内）。 &lt;server&gt; &lt;id&gt;192.168.197.143:5000&lt;/id&gt; &lt;username&gt;shitou&lt;/username&gt; &lt;password&gt;123&lt;/password&gt; &lt;/server&gt; 读者在配置上述服务认证信息时，注意修改自己本地私有仓库的地址id以及登录认证用户 的用户名和密码。配置完成后，就可以将微服务项目microservice-mallmanagement复制到managerl服 务主机的某个工作目录下，并进入到该项目pom文件所在位置（最外层的pom文件目录）， 然后使用mvn install指令进行打包(首次打包会进行pom依赖文件的下载，所以需要一定的 时间) 如果出现 HBUILD SUCCESS信息，就表示打包、镜像构建和推送成功。 如果某个过程执行失败，也可以从终端页面查看错误信息。当确定全部执行成功后，我们还可以实际确认。先通过docker images指令查看镜像列表中 是否有生成的指定镜像，然后再次进入本地私有镜像仓库配置的挂载目录/mnt/registry/docker/ registry/v2/repositories进行确认，查看生成的镜像是否也推送到了本地仓库。在Docker机器上正式打包部署时，项目配置文件中的服务地址将不再是localhost的本地连接，需 要按照第9章介绍微服务项目整合时的配置文件提示进行相应修改。5.微服务的手动部署 非集群环境下的服务部署就是将整个微服务项目运行在单个Docker主机环境下。这里先在managerl机器上安装DockerCompose编排工具（参考10.1.2小节）,通过该编排工具执行docker-compose.yml文件进行非集群环境下的服务部。具体部署服务过程如下。1.登录私有仓库 由于此次部署的微服务所需的镜像都存放在本地私有镜像仓库，并且本地私有仓库配置有用户认证，所以想要通过本地私有仓库的镜像部署服务，就必须先登录认证，获取镜像的使用权限（DockerHub远程仓库镜像则不需要登录认证）具体操作指令如下。$ docker login 192.168.197.143:5000执行上述指令就可以登录到指定服务地址的Docker Registry本地私有镜像仓库了。此后该 Docker机器就会处于持续认证状态，我们可以使用docker logout 192.168.197.143:5000指令 退出认证。2.部署服务进入到项目docker-compose.yml文件所在目录下，执行服务部署指令来部署整个微服务 项目，具体指令如下。$ docker-compose up 使用docker-compose up指令是在前台部署整个服务，终端窗口会打印出所有启动信息。 如果不想看到这些信息，还可以使用docker-compose up -d指令在后台部署服务。当服务部署完成后，可以通过docker ps指令查看所有服务是否都已正常运行（多个相互依 赖的服务同时部署过程可能需要一定的时间）， 所有的服务都已正常启动。此时，容器中对应的应用也已可以正常访问（后续会介绍具体的测试方式）。当不再需要某个服务时，可以在项目docker-compose.yml文件所在同级目录下使用结束指令结束整个服务，具体操作指令下$ docker-compose down6.使用Jenkins自动部署微服务 Jenkins官网提供了多种安装方式，包括基于Java的war包，Linux、MacOS和Windows系统等方式。这里我们选择比较通用的war包方式为例，在集群管理节点managerl机器上安装—Jenkins工具(由于Jenkins是由java开发的，所以在安装Jenkins之前要确保已安装了JDK并配置了系统环境)，具体步骤如下。1.下载 Jenkins在浏览器中输入Jenkins官网地址https://jenkins.io/download/访问其下载页面，选中页面 中 Long-term Support ( LTS,长期支持)版本最下方的 Generic java package ( .war),进行 Jenkins的war包下载，如图10-13所示。2.启动Jenkins服务将下载好的jenkins.war放到managerl机器中的某个目录下，直接使用如下指令即可启动 Jenkins 服务。$ java -jar jenkins.war -一httpPort=49001执行上述指令后，就会在Linux系统上通过war包的方式启动Jenkins服务。需要注意的是，Jenkins内部默认配置的端口是8080 (这与开发中很多端口有冲突),所以 我们在启动Jenkins服务时，使用一httpPort参数指定了服务启动的端口为49001 3.Jenkins初始化安装 通过浏览器访问地址http://192.168.197.143:49001就可以正式访问Jenkins服务，在首次安装访问Jenkins时，会涉及Jenkins的初始化安装输入初始化认证密码后，会进入一个Jenkins插件定制安装界面，这也是首次启动访问 Jenkins时会出现的页面，页面中会提供Install suggested plugins （安装建议插件）和Select plugins to install（自行选择插件安装）两种方式，通常情况下，都会选择左侧的Install suggested plugins进行初始化插件安装5.Jenkins集成插件配置1,安装Maven插件 因为我们之前创建的微服务是Maven项目，在使用Jenkins时也需要创建一个Maven项目 进行持续集成，所以这里需要配置Maven插件。依次单击主页面的“系统管理”今“插件管理”今“可选插件”面板，然后在右侧搜索框输 入&quot;Maven Integration plugin&quot;关键字进行搜索。搜索出结果后，选中该插件，并单击下方的“直 接安装”按钮，即可进行Maven插件安装，其效果如图10-18所示。2,系统全局插件配置完成所需插件的安装后，必须在Jenkins ±进行全局插件配置，这样才能让Jenkins与其他 软件关联工作，这里配置的全局插件主要有JDK （项目编译工具）、Git （代码仓库GitHub管理 工具）、Maven （项目打包工具）和Docker （项目部署工具）。6.服务自动化部署 1.构建新任务 构建一个maven项目 2.源码管理”中选择Git 并在Repository URL中输入该项目所在 的GitHub源码地址 3.构建触发器 Build periodically 表示在某个时间点进行自动任务构建，比如&quot;H 2 * * *&quot;表示每天凌 晨2点开始执行项目构建（不管项目是否更新） PollSCM 表示每隔一段时间会自动检查更新进行任务构建，比如“*/10****”表示每 10分钟开始检查源码，如果有更新就自动执行构建。 当默认没有进行构建触发器配置时我们可以在对应的任务面板中选择“立即构建”按钮， 随时进行手工触发任务构建。 4.服务发布配置 在Post Steps （服务发布配置）页面，选择&quot;Add post-build step&quot;下拉列表中的&quot;Execute shell&quot;选项，并在命令框中输入需要发布服务的shell指令 docker stack deploy -c docker-compose-swarm.yml --with-registry-auth mallmanagement docker stack deploy -c docker-compose-swarm.yml 表示使用当前目录下 的docker-compose-swarm.yml展件部署服务到当前主机所在集群中； --with-registry-auth 参数是对该集群下的所有节点进行通知，表示所有节点要到指定的本地私有仓库拉取镜像来启动服务（如果使用的是Docker Hub镜像仓库，此参数可省略）； mallmanagement是自定义的整 个集群服务的总名称。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell 常用脚本]]></title>
    <url>%2F2019%2F12%2F12%2FShell%20%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Shell 脚本 输入参数 并判断是否存在12345678910111213141516171819202122232425262728293031server_array[0]=server1server_array[1]=server2font=&quot;\E[34m\033[01m&quot;end=&quot;\E[0m&quot;if [ ! -n &quot;$1&quot; ] ;then echo -e &quot;$&#123;font&#125; you have not enter a server name ! such like : sh xxx.sh servername $&#123;end&#125;&quot; exit 1;fiflag=0for var in $&#123;server_array[@]&#125;;do if [ $var == &quot;$1&quot; ];then flag=1 fidoneif [ &quot;$flag&quot; -eq 1 ];then echo -e &quot;$&#123;font&#125; $1 $&#123;end&#125;&quot;else echo -e &quot;$&#123;font&#125; Error Server Name!!!! $&#123;end&#125;&quot;fi]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker介绍]]></title>
    <url>%2F2019%2F11%2F20%2FDocker%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[Docker Docs 1Docker是一个开源的应用容器引擎。Docker可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的Linux机器上，也可以实现虚拟化。容器是完全使用沙箱机制相互之间不会有任何接口（类似 iPhone的app）,更重要的是容器性能开销极低。 Docker的应用场景 Web 应用的自动化打包和发布。 自动化测试和持续集成、发布。 在服务型环境中部署和调整数据库或其他的后台应用。 从头编译或者扩展现有的 OpenShift 或 Cloud Foundry 平台来搭建自己的 PaaS 环境。 Docker 的优点Docker 是一个用于开发，交付和运行应用程序的开放平台。Docker 使您能够将应用程序与基础架构分开，从而可以快速交付软件。借助 Docker，您可以与管理应用程序相同的方式来管理基础架构。通过利用 Docker 的方法来快速交付，测试和部署代码，您可以大大减少编写代码和在生产环境中运行代码之间的延迟。 1、快速，一致地交付您的应用程序Docker 允许开发人员使用您提供的应用程序或服务的本地容器在标准化环境中工作，从而简化了开发的生命周期。容器非常适合持续集成和持续交付（CI / CD）工作流程，请考虑以下示例方案：您的开发人员在本地编写代码，并使用 Docker 容器与同事共享他们的工作。他们使用 Docker 将其应用程序推送到测试环境中，并执行自动或手动测试。当开发人员发现错误时，他们可以在开发环境中对其进行修复，然后将其重新部署到测试环境中，以进行测试和验证。测试完成后，将修补程序推送给生产环境，就像将更新的镜像推送到生产环境一样简单。 2、响应式部署和扩展Docker 是基于容器的平台，允许高度可移植的工作负载。Docker 容器可以在开发人员的本机上，数据中心的物理或虚拟机上，云服务上或混合环境中运行。Docker 的可移植性和轻量级的特性，还可以使您轻松地完成动态管理的工作负担，并根据业务需求指示，实时扩展或拆除应用程序和服务。 3、在同一硬件上运行更多工作负载Docker 轻巧快速。它为基于虚拟机管理程序的虚拟机提供了可行、经济、高效的替代方案，因此您可以利用更多的计算能力来实现业务目标。Docker 非常适合于高密度环境以及中小型部署，而您可以用更少的资源做更多的事情。 镜像(Image)就相当于是一个 root 文件系统。比如官方镜像 ubuntu:16.04就包含了完整的一套 Ubuntu16.04 最小系统的 root 文件系统。 容器(Container)镜像(Image)和容器(Container)的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 仓库(Repository)仓库可看着一个代码控制中心，用来保存镜像。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Logback]]></title>
    <url>%2F2019%2F11%2F19%2FLogback%2F</url>
    <content type="text"><![CDATA[标签123456appender:定义了打印过滤的条件、打印输出方式、滚动策略、编码方式、打印格式等等root: 是根loggerlogger: 指定某些应用具体的日志输出方式scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 Appender12345678910111213141516171819202122232425262728293031323334353637383940 appender:种类 1.ConsoleAppender：把日志添加到控制台 2.FileAppender：把日志添加到文件 3.RollingFileAppender：滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件。它是FileAppender的子类appender过滤器: 1.ThresholdFilter临界值过滤器，过滤掉低于指定临界值的日志。当日志级别等于或高于临界值时，过滤器返回NEUTRAL；当日志级别低于临界值时，日志会被拒绝 &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;/filter&gt; 2.LevelFilter级别过滤器，根据日志级别进行过滤。如果日志级别等于配置级别，过滤器会根据onMath(用于配置符合过滤条件的操作) 和 onMismatch(用于配置不符合过滤条件的操作)接收或拒绝日志。 &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; DENY：日志将立即被抛弃不再经过其他过滤器 NEUTRAL：有序列表里的下个过滤器过接着处理日志 ACCEPT：日志会被立即处理，不再经过剩余过滤器 appender file 子标签： 标签用于指定被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。 &lt;file&gt; $&#123;logging.path&#125;/glmapper-spring-boot/SERVICE-USER.log &lt;/file&gt;rollingPolicy 子标签 这个子标签用来描述滚动策略的。这个只有appender的class是RollingFileAppender时才需要配置。这个也会涉及文件的移动和重命名（a.log-&gt;a.log.2018.07.22）。 TimeBasedRollingPolicy 最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动。这个下面又包括了 FileNamePattern 日志文件输出的文件名:按天回滚 daily maxHistory 日志文件保留天数encoder 子标签 记录事件进行格式化。它干了两件事： 把日志信息转换成字节数组 把字节数组写入到输出流 &lt;encoder class=&quot;ch.qos.logback.classic.encoder.PatternLayoutEncoder&quot;&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125;- %msg%n&lt;/pattern&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;/encoder&gt; logger123456789 &lt;logger name=&quot;com.spring.boot.controller&quot; level=&quot;$&#123;logging.level&#125;&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;SERVICE-USER&quot; /&gt; &lt;/logger&gt;上面的这个配置文件描述的是：com.spring.boot.controller这个包下的$&#123;logging.level&#125;级别的日志将会使用SERVICE-USER来打印。 name:用来指定受此logger约束的某一个包或者具体的某一个类。 level:用来设置打印级别（TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF），还有一个值INHERITED或者同义词NULL，代表强制执行上级的级别。如果没有设置此属性，那么当前logger将会继承上级的级别。 addtivity:用来描述是否向上级logger传递打印信息。默认是true。 示例&lt;!--每个logger都关联到logger上下文，默认上下文名称为“default”。但可以使用contextName标签设置成其他名字，用于区分不同应用程序的记录--&gt; &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;configuration scan=&quot;false&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; &lt;!-- 定义日志的根目录 --&gt; &lt;property name=&quot;LOG_HOME&quot; value=&quot;/app/log&quot; /&gt; &lt;!-- 定义日志文件名称 --&gt; &lt;property name=&quot;appName&quot; value=&quot;nasus-springboot&quot;&gt;&lt;/property&gt; &lt;!-- ch.qos.logback.core.ConsoleAppender 表示控制台输出 --&gt; &lt;appender name=&quot;stdout&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;!-- 日志输出格式： %d表示日期时间， %thread表示线程名， %-5level：级别从左显示5个字符宽度 %logger{50} 表示logger名字最长50个字符，否则按照句点分割。 %msg：日志消息， %n是换行符 --&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;springProfile name=&quot;dev&quot;&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} ----&gt; [%thread] ---&gt; %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;springProfile name=&quot;!dev&quot;&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} ==== [%thread] ==== %-5level %logger{50} - %msg%n&lt;/pattern&gt; &lt;/springProfile&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;!-- 滚动记录文件，先将日志记录到指定文件，当符合某个条件时，将日志记录到其他文件 --&gt; &lt;appender name=&quot;appLogAppender&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 指定日志文件的名称 --&gt; &lt;file&gt;${LOG_HOME}/${appName}.log&lt;/file&gt; &lt;!-- 当发生滚动时，决定 RollingFileAppender 的行为，涉及文件移动和重命名 TimeBasedRollingPolicy： 最常用的滚动策略，它根据时间来制定滚动策略，既负责滚动也负责出发滚动。 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;!-- 滚动时产生的文件的存放位置及文件名称 %d{yyyy-MM-dd}：按天进行日志滚动 %i：当文件大小超过maxFileSize时，按照i进行文件滚动 --&gt; &lt;fileNamePattern&gt;${LOG_HOME}/${appName}-%d{yyyy-MM-dd}-%i.log&lt;/fileNamePattern&gt; &lt;!-- 可选节点，控制保留的归档文件的最大数量，超出数量就删除旧文件。假设设置每天滚动， 且maxHistory是365，则只保存最近365天的文件，删除之前的旧文件。注意，删除旧文件是， 那些为了归档而创建的目录也会被删除。 --&gt; &lt;MaxHistory&gt;365&lt;/MaxHistory&gt; &lt;!-- 当日志文件超过maxFileSize指定的大小是，根据上面提到的%i进行日志文件滚动 注意此处配置SizeBasedTriggeringPolicy是无法实现按文件大小进行滚动的，必须配置timeBasedFileNamingAndTriggeringPolicy --&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP&quot;&gt; &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;!-- 日志输出格式： --&gt; &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [ %thread ] - [ %-5level ] [ %logger{50} : %line ] - %msg%n&lt;/pattern&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;!-- logger主要用于存放日志对象，也可以定义日志类型、级别 name：表示匹配的logger类型前缀，也就是包的前半部分 level：要记录的日志级别，包括 TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR additivity：作用在于children-logger是否使用 rootLogger配置的appender进行输出， false：表示只用当前logger的appender-ref，true： 表示当前logger的appender-ref和rootLogger的appender-ref都有效 --&gt; &lt;!-- hibernate logger --&gt; &lt;logger name=&quot;com.nasus&quot; level=&quot;debug&quot; /&gt; &lt;!-- Spring framework logger --&gt; &lt;logger name=&quot;org.springframework&quot; level=&quot;debug&quot; additivity=&quot;false&quot;&gt;&lt;/logger&gt; &lt;!-- root 与 logger 是父子关系，没有特别定义则默认为root，任何一个类只会和一个logger对应， 要么是定义的logger，要么是root，判断的关键在于找到这个logger，然后判断这个logger的appender和level。 --&gt; &lt;root level=&quot;info&quot;&gt; &lt;appender-ref ref=&quot;stdout&quot; /&gt; &lt;appender-ref ref=&quot;appLogAppender&quot; /&gt; &lt;/root&gt; &lt;/configuration&gt;]]></content>
      <categories>
        <category>Logback</category>
      </categories>
      <tags>
        <tag>Logback</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Btrace 远程调试]]></title>
    <url>%2F2019%2F11%2F13%2FBtrace%20%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[Btrace GitHub链接 下载Btrace到本地1234567891011121314151617181920212223$ wget https://github.com/btraceio/btrace/releases/download/v1.3.11.3/btrace-bin-1.3.11.3.zip$ unzip btrace-bin-1.3.11.3.zip -d ./btrace //解压到指定文件夹$ vim /etc/profileexport BTRACE_HOME=/home/btrace; ## btrace安装目录export PATH=$PATH:$BTRACE_HOME/bin;$ btrace --versionBTrace v.1.3.11.3 (20181217)$ jps //查看Java项目进程Pid 也可以 ps -ef |grep xxx13890 Bootstrap$ cd /home/btrace/bin$ btrace 13890 ../samples/AllMethods.java //btrace &lt;PID&gt; XXX.java 执行命令 属性注解1@TLS标注的属性可以在追踪脚本的方法中通讯 方法注解1234567891011@OnMethod:指定该方法在什么情况下被执行，clazz属性指定要跟踪的类的全限定类名，也可以用正则表达式， “/类名的Pattern/”匹配，如/javax\\.swing\\..*/；用”+类名”追踪所有子类， 如+java.lang.Runnable；用”@xxx”追踪用该注解注解过的类， 如@javax.jws.WebService。method属性指定要追踪的方法名称，也可以用正则表达式。 location属性用@Location来指定该方法在目标方法执行前(后、异常、某行、某个方法调用)被执行。@OnTimer:定时执行该方法。@OnExit:当脚本运行Sys.exit(code)时执行该方法。@OnError:当脚本运行抛出异常时执行该方法。@OnEvent:脚本运行时Ctrl+C可以发送事件。@OnLowMemory:指定一个内存阀值，低于阀值值执行该方法。@OnProbe:指定一个xml文件来描述在什么时候执行该方法。 方法参数注解12345678@Self:指目标对象本身。@Retrun:指目标程序方法返回值(需要配合Kind.RETURN)。@ProbeClassName:指目标类名。@ProbeMethodName:指目标方法名。@targetInstance:指@Location指定的clazz和method的目标(需要配合Kind.CALL)。@targetMethodOrField:指@Location指定的clazz和method的目标的方法或字段(需要配合Kind.CALL)。@Duration:指目标方法执行时间，单位是纳秒(需要需要配合Kind.RETURN或Kind.ERROR一起使用）。AnyType:获取对应请求的参数，泛指任意类型。 追踪时机参数12345678Kind.Entry:开始进入目标方法时，默认值?。Kind.Return:目标方法返回时。Kind.Error:异常没被捕获被抛出目标方法之外时?。Kind.Throw:异常抛出时?。Kind.Catch:异常被捕获时。Kind.Call:被调用时。Kind.Line:执行到某行时。 Btrace 实例Demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import com.sun.btrace.annotations.*;import com.sun.btrace.services.impl.Printer;import com.sun.btrace.AnyType;import com.sun.btrace.BTraceUtils;import java.lang.reflect.Field;/** * 拦截时机 * 不写Location,默认就是刚进入函数的时候(Kind.ENTRY) * 异常抛出(Throw), * 异常被捕获(Catch), * 异常没被捕获被抛出函数之外(Error),主要用于对某些异常情况的跟踪。 * clazz 类名 * method 方法名 */@BTracepublic class DappDemo &#123; @Injected(ServiceType.RUNTIME) private static Printer printer; @TLS static long beginTime; @OnMethod(clazz = &quot;com.xxx&quot;, method = &quot;xxx&quot;) public static void getTime() &#123; beginTime = BTraceUtils.timeMillis(); &#125; @OnMethod(clazz = &quot;com.xxx&quot;, method = &quot;xxx&quot;, location = @Location(value = Kind.RETURN)) public static void btraceDemo(@Self Object self,Integer chain, @ProbeClassName String probeClass, @ProbeMethodName String probeMethod, @Return AnyType result) &#123; //打印耗时 printer.println(&quot; 耗时---&gt;[&quot; + (BTraceUtils.timeMillis() - beginTime) + &quot;]&quot; + &quot; ms&quot;); //打印类名 printer.println(&quot; ClassName---&gt;[&quot; + probeClass + &quot;]&quot;); //打印方法名 printer.println(&quot;MethodName---&gt;[&quot; + probeMethod + &quot;]&quot;); //打印入参 printer.println(&quot; Param---&gt;chain: [&quot; + chain + &quot;]&quot;); printer.println(&quot; Result---&gt;[&quot; + result); printer.println(&quot;当前Name属性值: &quot; +BTraceUtils.get(BTraceUtils.field(BTraceUtils.classForName(&quot;com.XXX&quot;,BTraceUtils.contextClassLoader()), name(属性昵称), result)); //打印耗时 printer.println(&quot; ==============&quot;); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Btrace</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Navicat Premium 12永久激活]]></title>
    <url>%2F2019%2F11%2F08%2FNavicat%20Premium%2012%E6%B0%B8%E4%B9%85%E6%BF%80%E6%B4%BB%2F</url>
    <content type="text"><![CDATA[一、下载Navicat Premium 12并安装 官网地址二、点击注册机下载三、激活Navicat Premium 1211、以管理员身份运行注册机 12、打开注册机后，在1) Patch，勾选Backup、Host和Navicat v12，然后点击Patch按钮： 123.找到Navicat Premium 12安装路径下的navicat.exe，选中并点击打开。此时出现如下弹窗，提示navicat.exe - x64 -&gt; Cracked.，提示已破解（别高兴，还没结束）。若提示libcc.dll或navicat.exe出错，检查是否未关闭Navicat Premium，或到安装目录下将libcc.dll和navicat.exe删除，并将libcc.dll.BAK或navicat.exe.BAK去掉.BAK后缀名。否则卸载已安装的Navicat Premium并清理文件残留和注册表残留： 14. Keygen / Offline Activation，点击Generate，将自动生成SerialKeygen(注册码) 15.打开Navicat Premium 12，点击菜单栏的帮助，选择注册，在注册窗口键处填入上一步生成的Serial Keygen（即注册码），然后点击激活： 126.点击手动激活：将Navicat手动激活窗口的请求码框中内容复制到注册机Request Code框中，点击Activation Code下面的Generate按钮（若此处出现错误，要么你未完全按照教程来，要么你所安装的版本高于注册机所支持的版本）： 17.将注册机Activation Code处生成的激活码内容复制到Navicat手动激活窗口的激活码框中（或点击Activation Code处下面的Copy按钮，这样会自动粘贴到Navicat手动激活窗口的激活码框中），然后点击激活按钮：]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux服务器如何禁用密码登录，使用秘钥文件登录增加服务器安全性？]]></title>
    <url>%2F2019%2F11%2F05%2FLinux%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%A6%82%E4%BD%95%E7%A6%81%E7%94%A8%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%EF%BC%8C%E4%BD%BF%E7%94%A8%E7%A7%98%E9%92%A5%E6%96%87%E4%BB%B6%E7%99%BB%E5%BD%95%E5%A2%9E%E5%8A%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E5%85%A8%E6%80%A7%2F</url>
    <content type="text"><![CDATA[生成秘钥公钥1234567891011121314151617181920212223242526272829303132333435363738394041$ ssh-keygen //生成秘钥Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:The key&apos;s randomart image is:+---[RSA 2048]----+| .o=B@*. || . = =o*.*. ||. . + @ + o o ||oo o * + ||o +.. + S ||.oo. . || =. ||..=oE || *+ o. |+----[SHA256]-----+$ cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys //把公钥放进授权文件中去$ cd /root/.ssh$ chmod 600 authorized_keys$ chmod 700 ~/.ssh$ vim /etc/ssh/sshd_configRSAAuthentication yesPubkeyAuthentication yesPermitRootLogin yes //另外，请留意 root 用户能否通过 SSH 登录，默认为yes： 当我们完成全部设置并以密钥方式登录成功后，可以禁用密码登录。这里我们先不禁用，先允许密码登陆PasswordAuthentication yes $ service sshd restart //重启服务 客户端使用秘钥登录1231. /root/.ssh/id_rsa 到Windwos桌面 更改为.pem文件 2.使用SecurtCRT SSH远程连接工具进行登录 3.登录成功后 请把/etc/ssh/sshd_config 文件中的PasswordAuthentication改为No 禁止密码进行远程登录 防止服务器被恶意SSH暴力破解攻击 服务器被攻击如图]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 安装 Elasticsearch Kibana Logstash]]></title>
    <url>%2F2019%2F11%2F02%2FLinux%20%20%E5%AE%89%E8%A3%85%20Elasticsearch%20Kibana%20Logstash%2F</url>
    <content type="text"><![CDATA[各系统安装说明 安装 ElasticSearch1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495 $ groupadd es //使用 root 用户启动 elasticsearch 会报错,用 root 用户新建 es$ useradd -g es es //新建 es 用户，并添加到 es用户组$ passwd es //设置 es 用户的用户密码，按照提示输入你的密码$ chown -R es:es /es //授权，我这里文件路径在 /es 下面$ vim /etc/sysctl.conf //编辑 #添加一行 vm.max_map_count=655360 $ sysctl -p //配置生效$ su es //切换用户 $ mkdir es$ cd es $ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.7.0.tar.gz$ tar -zxvf elasticsearch-6.7.0.tar.gz //解压文件#es 作为集群，应该至少 3 个节点，这里服务器内存只有 2G，部署一个单机版 3 节点的伪集群$ mv elasticsearch-6.7.0-node elasticsearch-6.7.0-node1 //给文件夹改名#修改配置文件,默认值为 1g，我这里改为 160m，否则服务器带不动$ cd elasticsearch-6.7.0-node1$ vim config/jvm.options -Xms160m -Xmx160m$ mkdir elasticsearch-6.7.0-data1 //新建文件夹存放数据和日志，默认存放于 es 安装目录，为了防止误删和被覆盖，另建文件夹$ cd elasticsearch-6.7.0-data1/$ mkdir data logs#修改配置文件(https://www.cnblogs.com/zhq1007/p/8482454.html)$ cd /es/elasticsearch-6.7.0-node1/config/$ vim elasticsearch.yml cluster.name: 你的集群名称 node.name: node-1 # 节点名称 其余两个节点分别为 node-2、node-3 node.master: true node.data: true bootstrap.memory_lock: true path.data: /opt/fangzhibin/es670/elasticsearch-6.7.0-data1/data # 其余两个节点为 data2/data、data3/data path.logs: /opt/fangzhibin/es670/elasticsearch-6.7.0-data1/logs # 其余两个节点为 data2/logs、data3/logs network.host: 0.0.0.0 transport.tcp.port: 9301 # 因为在同一台服务器，其余两个节点分别为 9302、9303 http.port: 9201 # 因为在同一台服务器，其余两个节点分别为 9202、9203 discovery.zen.ping.unicast.hosts: [&quot;节点IP:9301&quot;,&quot;节点IP:9302&quot;,&quot;节点IP:9303&quot;] # discovery.zen.minimum_master_nodes: 2 # 根据主节点数量计算：主节点数量/2 + 1；3 个节点则设置为 2$ cd /es/elasticsearch-6.7.0-node1$ bin/elasticsearch -d#验证是否正常启动 node1（或者浏览器访问 http://你的IP:9201）curl &quot;http://你的IP:9201&quot;#出现以下内容即可，node2 和node3 同理 &#123; &quot;name&quot; : &quot;node-1&quot;, &quot;cluster_name&quot; : &quot;cluster-aly&quot;, &quot;cluster_uuid&quot; : &quot;RixPnO6hTQClAqxlAt_v2g&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;6.7.0&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;, &quot;build_hash&quot; : &quot;8453f77&quot;, &quot;build_date&quot; : &quot;2019-03-21T15:32:29.844721Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;7.7.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot; &#125;#正常启动 node1 后，复制节点$ cd /es$ cp -r elasticsearch-6.7.0-data1 elasticsearch-6.7.0-data2$ cp -r elasticsearch-6.7.0-node1 elasticsearch-6.7.0-node2$ cp -r elasticsearch-6.7.0-data1 elasticsearch-6.7.0-data3$ cp -r elasticsearch-6.7.0-node1 elasticsearch-6.7.0-node3#注意：按照上面的配置项说明更改 node2、node3 的配置文件#启动 node2 和 node3$ cd /es/elasticsearch-6.7.0-node2$ bin/elasticsearch -d$ cd /es/elasticsearch-6.7.0-node3$ bin/elasticsearch -d#验证是否正常启动，参考上面 elasticsearch 默认配置1234567891011121314151617181920#集群名称cluster.name: elasticsearch_production#该节点名称node.name: elasticsearch_001_data#数据存放目录path.data: /home/elasticsearch-6.7.0-data1/data#日志存放目录path.logs: /home/elasticsearch-6.7.0-data1/logs#是否可以被选举为master节点node.master: true#是否为data nodenode.data: true#端口http.port: 9200 安装 Kibana12345678910111213141516### Kibana 是一款开源的数据分析和可视化平台，它是 Elastic Stack 成员之一，设计用于和 Elasticsearch 协作。您可以使用 Kibana 对 Elasticsearch 索引中的数据进行搜索、查看、交互操作。您可以很方便的利用图表、表格及地图对数据进行多元化的分析和呈现。#同样使用 es 用户$ cd /es$ wget https://artifacts.elastic.co/downloads/kibana/kibana-6.7.0-linux-x86_64.tar.gz$ tar -zxvf kibana-6.7.0-linux-x86_64.tar.gz$ mv kibana-6.7.0-linux-x86_64 kibana$ cd kibana$ vim config/kibana.yml# 更改如下配置# 配置参考官方文档：https://www.elastic.co/guide/cn/kibana/current/settings.html server.host: &quot;0.0.0.0&quot; # 指定后端服务器的主机地址 i18n.locale: &quot;zh-CN&quot; #汉化 elasticsearch.hosts: [&quot;http://localhost:9201&quot;] # 所有 Elasticsearch 实例的 URL，用逗号分隔 $ nohup /es/kibana/bin/kibana &gt; /es/kibana/kibana.log &amp; //启动 kibana 浏览器访问： http://Kibana服务器IP:5601 安装 Logstash12345678910111213141516171819202122232425262728293031323334353637383940414243$ mkdir /es/logstash$ cd /es/logstash$ wget https://artifacts.elastic.co/downloads/logstash/logstash-6.3.0.zip$ unzip logstash-6.3.0.zip$ mv logstash-6.3.0 logstash$ cd logstash $ bin/logstash -f config/xxx.conf &gt; /es/logstash/logstash.log &amp; //启动 Logstash启动时需要指定配置监控日志策略的文件，xx.conf放在ELK\logstash\config目录下简单的配置说明input &#123; tcp &#123; mode =&gt; &quot;server&quot; #模式 host =&gt; &quot;localhost&quot;#服务器IP port =&gt; 900 #端口 codec =&gt; json_lines #JSON格式 &#125;&#125;output&#123; elasticsearch &#123; action =&gt; &quot;index&quot; hosts =&gt; [&quot;localhost:9200&quot;] #Elasticsearch服务的IP和端口 index =&gt; &quot;applog&quot; #Kibana管理中搜索所使用的索引名 &#125; stdout &#123; codec =&gt; rubydebug &#125; &#125; 最终效果图]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
        <tag>Logstash</tag>
        <tag>Kibana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 常用命令]]></title>
    <url>%2F2019%2F10%2F29%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux 命令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374$ curl cip.cc # 查看公网IP $ curl http://ifconfig.me$ lsb_release -a #查看Linux版本$ lsof | grep deleted #查看删除进程$ df -h #查看磁盘空间 $ du -h --max-depth=2 | sort -n | head -12 #查找排在前12的大文件夹$ scp -P 22 ./xxx.txt root@127.0.0.1:/home/xxx #SCP上传文件到指定服务器$ scp -P 22 -r ./xxx root@127.0.0.1:/home/xxx #SCP上传文件夹到指定服务器$ scp -P 22 -r root@127.0.0.1:/home/xxx /home/xxx #SCP下载服务器文件夹到本地$ scp -P 22 root@127.0.0.1:/home/xxx.txt /home/xxx #SCP下载服务器文件到本地$ netstat -tunlp |grep 8443 #查看端口占用$ chmod 777 xxx.sh #赋予脚本执行权$ ps -aux | sort -rnk 3 | head -20 #找出当前系统CPU使用量较高的进程 $ ps -aux|grep java //查看java进程$ ps -aux //查看所有进程$ tree a -L 2 //以树状格式列出目录 -L n n表示只显示到第几层$ wget http://file.tgz //文件下载 $ curl http://file.tgz //请求URL$ ping www.just-ping.com //网络检测$ tar -czf test.tar.gz /test1 /test2 //列出压缩文件列表$ tar -tzf test.tar.gz //解压文件$ tar -xvzf test.tar.gz //解压文件$ head -n 10 example.txt //查看文件前10行$ tail -n 10 example.txt //查看文件后10行 $ tail -f exmaple.log //查看日志最近更新$ netstat -tunlp | grep 8080 查看端口8080的使用情况 //查看端口占用情况$ lsof -i :8080 //查看端口属于哪个进程$ chmod 777 file.java file.java的权限-rwxrwxrwx，r表示读、w表示写、x表示可执行##赋予执行权 $ chmod 777 xxx.sh $ grep -H &apos;spring&apos; *.xml //查找所以有的包含spring的xml文件$ ls -l | grep &apos;.jar&apos; //查找当前目录中的所有jar文件$ grep &apos;test&apos; d* //显示所有以d开头的文件中包含test的行$ grep &apos;test&apos; aa bb cc //显示在aa，bb，cc文件中匹配test的行$ grep &apos;[a-z]\&#123;5\&#125;&apos; aa #显示所有包含每个字符串至少有5个连续小写字符的字符串的行$ ps –ef|grep tomcat //查看所有有关tomcat的进程$ ps -ef|grep --color java //高亮要查询的关键字$ kill -9 19979 //终止线程号位19979的进程 Linux 限制Root 指定IP登陆1234$ vim /etc/ssh/sshd_config //编辑ssh的配置文件默认 /etc/ssh/sshd_config，在文件最后面另起一行添加AllowUsers root@183.21.89.249$ service sshd restart //保存并退出，再重启一下ssh服务 Linux 修改SSH端口123$ vim /etc/ssh/sshd_config //找到#Port 22字段 删掉#，将22改为其他不被使用的端口Port 22$ service sshd restart //保存并退出，再重启一下ssh服务 find(查找文件)12345678910111213$ find / -name *sync-huobi* $ find / -name filename.txt //根据名称查找/目录下的filename.txt文件。$ find . -name &quot;*.xml&quot; //递归查找所有的xml文件$ find . -name &quot;*&quot; |xargs grep &quot;hello&quot; //递归查找所有文件内容中包含hello world的xml文件$ find . -type f -size +100M -print0 | xargs -0 du -h | sort -nr //(https://www.cnblogs.com/kerrycode/p/4391859.html) #查找大文件$ find ./ -size 0 | xargs rm -f &amp; //删除文件大小为零的文件$ find / -name *.conf -type f -print | xargs tar cjf test.tar.gz #tar命令将找出的文件直接打包 用户命令12345678 $ sudo rm a.txt 使用管理员身份删除文件$ userdel -r xxx 完全删除用户$ chown -R ubuntu /var/lib/mysql //给指定用户加权限$ chown -R ubuntu:root /home/ubuntu //给指定用户加权限 Redis (查看大Key)1redis-cli -h IP -p 6379 -a password --bigkeys 启动SpringBoot Jar1nohup java -jar exchange-announcement-0.0.1-SNAPSHOT.jar &gt; /home/logs/xxx.log &amp; //后台启动一个Jar包 输出日志到指定文件 安装反编译工具 反编译python12pip install uncompyle 安装反编译工具 反编译pythonuncompyle6 upload_photo.pyc upload_photo.py 阿里云挂载磁盘123456$ mount /dev/vdb1 /clouddisk ##将云盘进行挂载(vdb是快照对应的盘符，需要到系统内确认是不是vdb1，挂载到 clouddisk目录)$ fuser -mv /clouddisk/ ##先杀死使用该目录的所有进程$ umount /dev/vdb1 ##在阿里云卸载云盘之前执行卸载操作 Vim 批量替换1$ %s#abc#123#g abc 替换为 123 //命令行]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Redis</tag>
        <tag>SpingBoot</tag>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 数据库表数据的快速迁移]]></title>
    <url>%2F2019%2F09%2F18%2FMysql%20%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E6%95%B0%E6%8D%AE%E7%9A%84%E5%BF%AB%E9%80%9F%E8%BF%81%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[表数据迁移 (前提:目标数据库和源数据库含有相同数据库名和表)1234567891011121314151617181920212223242526mysql&gt; ALTER TABLE t_app_banner DISCARD TABLESPACE; //目标数据库.ibd文件与原先的.frm文件解除绑定 $ cd /var/lib/mysql //mysql数据库文件存放位置 在/etc/mysql/mysql.conf.d中查看$ lsauto.cnf test debian-5.7.flag ib_buffer_pool ibdata1 ib_logfile0 ib_logfile1 ibtmp1 mysql performance_schema sys$ls -lhttotal 144K-rw-r----- 1 mysql mysql 9.1K Sep 18 08:00 t_app_banner.frm-rw-r----- 1 mysql mysql 67 Sep 18 03:00 db.opt-rw-rw-r-- 1 mysql mysql 128K Sep 16 06:50 t_app_banner.ibd$ 复制要恢复表的.ibd文件 至目标数据库的相同目录下进行覆盖$cd /var/lib/mysql/test$ ls -lhttotal 144K-rw-r----- 1 mysql mysql 9.1K Sep 18 08:00 t_app_banner.frm-rw-r----- 1 mysql mysql 67 Sep 18 03:00 db.opt-rw-rw-r-- 1 ubuntu ubuntu 128K Sep 16 06:50 t_app_banner.ibd //如果该文件使用者为ubuntu需要进行权限更改$ chown mysql:mysql /var/lib/mysql/test -R //修改t_app_banner.ibd的授权用户$mysql&gt; ALTER TABLE t_app_banner IMPORT TABLESPACE; //恢复ibd和frm文件的关联]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 安装Maven]]></title>
    <url>%2F2019%2F08%2F30%2FLinux%20%E5%AE%89%E8%A3%85Maven%2F</url>
    <content type="text"><![CDATA[Maven官网下载地址 ######安装 Java12345678$ sudo apt-get update$ sudo apt-get install openjdk-8-jdk$ java -versionopenjdk version &quot;1.8.0_232&quot;OpenJDK Runtime Environment (build 1.8.0_232-8u232-b09-0ubuntu1~18.04.1-b09)OpenJDK 64-Bit Server VM (build 25.232-b09, mixed mode) 12345678910111213141516171819202122232425262728$ wget http://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.2/binaries/apache-maven-3.6.2-bin.tar.gz--2019-09-06 16:35:40-- http://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.2/binaries/apache-maven-3.6.2-bin.tar.gzResolving mirrors.tuna.tsinghua.edu.cn... 101.6.8.193, 2402:f000:1:408:8100::1Connecting to mirrors.tuna.tsinghua.edu.cn|101.6.8.193|:80... connected.HTTP request sent, awaiting response... 200 OKLength: 9142315 (8.7M) [application/x-gzip]Saving to: “apache-maven-3.6.2-bin.tar.gz”100%[================================================================================================================================================&gt;] 9,142,315 630K/s in 16s 2019-09-06 16:35:56 (552 KB/s) - “apache-maven-3.6.2-bin.tar.gz” saved [9142315/9142315]$ lsapache-maven-3.6.2-bin.tar.gz bin include jdk lib lib64 libexec records sbin share src$ tar zxvf apache-maven-3.6.2-bin.tar.gz $ mv apache-maven-3.6.2 maven$ vim /etc/profile //尾部添加 配置环境变量MAVEN_HOME=/usr/local/mavenPATH=$PATH:$MAVEN_HOME/binexport MAVEN_HOMEexport PATH$ source /etc/profile$ mvn -v //验证是否安装成功Apache Maven 3.6.2 (40f52333136460af0dc0d7232c0dc0bcf0d9e117; 2019-08-27T23:06:16+08:00)Maven home: /usr/local/mavenJava version: 1.8.0_45, vendor: Oracle Corporation, runtime: /usr/local/jdk/jreDefault locale: en_US, platform encoding: UTF-8OS name: &quot;linux&quot;, version: &quot;2.6.32-754.12.1.el6.x86_64&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot;]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 安装Jenkins、Linux启动多个Tomcat、安装JDK]]></title>
    <url>%2F2019%2F08%2F30%2FLinux%20%E5%AE%89%E8%A3%85Jenkins%E3%80%81Linux%E5%90%AF%E5%8A%A8%E5%A4%9A%E4%B8%AATomcat%E3%80%81%E5%AE%89%E8%A3%85JDK%2F</url>
    <content type="text"><![CDATA[安装Java(略)1234567891011121314151617181920$ tar zxvf jdk-8u231-linux-x64.tar.gz //下载 jdk-8u231-linux-x64.tar.gz 解压到/usr/local/java$ vim /etc/profile 配置环境变量 export JAVA_HOME=/usr/local/javaexport JRE_HOME=$&#123;JAVA_HOME&#125;/jre export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH$ source /etc/profile$ java -versionjava version &quot;1.8.0_45&quot;Java(TM) SE Runtime Environment (build 1.8.0_45-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode)$ echo $JAVA_HOME ##输出Java安装目录/usr/local/jdk Linux启动多个Tomcat123456789101112131415161718192021222324$ vim /etx/profile##########first tomcat###########CATALINA_BASE=/home/tomcat-1CATALINA_HOME=/home/tomcat-1TOMCAT_HOME=/home/tomcat-1export CATALINA_BASE CATALINA_HOME TOMCAT_HOME##########first tomcat#####################second tomcat##########CATALINA2_BASE=/home/tomcat-2CATALINA2_HOME=/home/tomcat-2TOMCAT2_HOME=/home/tomcat-2export CATALINA2_BASE CATALINA2_HOME TOMCAT2_HOME##########second tomcat##########$ vim /home/tomcat-data/bin/catalina.sh //找到OS specific support 在下面添加# OS specific support. $var _must_ be set to either true or false.export CATALINA_BASE=$CATALINA2_BASEexport CATALINA_HOME=$CATALINA2_HOME$ vim /home/tomcat-2/conf/server.xml // 修改 conf/server.xml 修改关闭端口 监听端口 访问端口 Ubuntu 安装jenkins123456789101112131415161718192021222324$ wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add -$ sudo sh -c &apos;echo deb http://pkg.jenkins.io/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list&apos;$ sudo apt-get update$ sudo apt-get install jenkins$ service jenkins status //jenkins服务状态$ service jenkins stop //启动jenkins$ service jenkins start //停止jenkins$ service jenkins restart //重启jenkins$ vim /etc/default/jenkins //修改以下属性为root # user and group to be invoked as (default to jenkins)JENKINS_USER=rootJENKINS_GROUP=root$ find / -name &quot;jenkins&quot; //查找jenkins目录 进行root授权$ chown -R root:root /usr/share/jenkins$ chown -R root:root /usr/share/doc/jenkins$ chown -R root:root /etc/init.d/jenkins$ chown -R root:root /etc/default/jenkins$ chown -R root:root /etc/logrotate.d/jenkins$ chown -R root:root /var/lib/jenkins$ chown -R root:root /var/cache/jenkins$ chown -R root:root /var/log/jenkins$ service jenkins stop //重启jenkins如果你的`/etc/init.d/jenkins`文件无法启动Jenkins，编辑`/etc/default/jenkins`， 修改 ----HTTP_PORT=8080----`为----HTTP_PORT=8081----` 在这里，“8081”也可被换为其他可用端口。ln -s /opt/jdk1.8.0_201/bin/java /usr/bin/java //创建java软连接 centos版本 安装Jenkins12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970$ sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo$ sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key$ yum install jenkinsLoaded plugins: fastestmirrorSetting up Install ProcessLoading mirror speeds from cached hostfilejenkins | 2.9 kB 00:00 jenkins/primary_db | 29 kB 00:00 Resolving Dependencies--&gt; Running transaction check---&gt; Package jenkins.noarch 0:2.176.3-1.1 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved=========================================================================================================================================================== Package Arch Version Repository Size===========================================================================================================================================================Installing: jenkins noarch 2.176.3-1.1 jenkins 74 MTransaction Summary===========================================================================================================================================================Install 1 Package(s)Total download size: 74 MInstalled size: 74 MIs this ok [y/N]: yDownloading Packages:jenkins-2.176.3-1.1.noarch.rpm | 74 MB 00:26 Running rpm_check_debugRunning Transaction TestTransaction Test SucceededRunning Transaction Installing : jenkins-2.176.3-1.1.noarch 1/1 Verifying : jenkins-2.176.3-1.1.noarch 1/1 Installed: jenkins.noarch 0:2.176.3-1.1 Complete!$ service jenkins start //启动JenkinsStarting Jenkins bash: /usr/bin/java: No such file or directory [FAILED]说明该目录下没有配置Java $ vi /etc/sysconfig/jenkins //修改一下默认端口(8080)和启动用户JENKINS_USER=&quot;root&quot;JENKINS_PORT=&quot;8081&quot;$ echo $JAVA_HOME ##输出Java安装目录/usr/local/jdk$ vim /etc/init.d/jenkins candidates=/etc/alternatives/java/usr/lib/jvm/java-1.8.0/bin/java/usr/lib/jvm/jre-1.8.0/bin/java/usr/lib/jvm/java-1.7.0/bin/java/usr/lib/jvm/jre-1.7.0/bin/java/usr/lib/jvm/java-11.0/bin/java/usr/lib/jvm/jre-11.0/bin/java/usr/lib/jvm/java-11-openjdk-amd64/usr/bin/java/usr/local/jdk/bin/java //增加Java安装目录$ service jenkins start //启动jenkins 成功Starting Jenkins [ OK ]$ cat /var/lib/jenkins/secrets/initialAdminPassword62ce0816e3c24d9aa3fac37a9a39fb4r 在浏览器输入ip:8080进入Jenkins登录页面。如图： 出现一下情况 1234解决方法： http://ip:8080/pluginManager/advanced Update Site 下的 http://updates.jenkins.io/update-center.json 修改为 https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json 之后 在浏览器输入 http://ip:8080/restart 再进入 http://ip:8080登陆即可正常$ service jenkins start //如果还不行 进行重启 如果出现登陆成功卡在空白页面 输入http://ip:8080/restart 进行重启 或 service jenkins start]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql开启log_bin并进行数据恢复]]></title>
    <url>%2F2019%2F08%2F29%2FMysql%E5%BC%80%E5%90%AFlog_bin%E5%B9%B6%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[Mysql开启binlog 日志类型 写入日志的信息 错误日志 记录在启动，运行或停止mysqld时遇到的问题 通用查询日志 记录建立的客户端连接和执行的语句 二进制日志 记录更改数据的语句 中继日志 从复制主服务器接收的数据更改 慢查询日志 记录所有执行时间超过 long_query_time 秒的所有查询或不使用索引的查询 DDL日志(元数据日志) 元数据操作由DDL语句执行 本文主要介绍二进制日志 binlog。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970Binlog日志的两个最重要的使用场景1.MySQL主从复制：MySQL Replication在Master端开启binlog，Master把它的二进制日志传递给slaves来达到master-slave数据一致的目的2.数据恢复：通过使用 mysqlbinlog工具来使恢复数据启用binlog，通过配置 /etc/my.cnf 或 /etc/mysql/mysql.conf.d/mysqld.cnf $ vim /etc/mysql/mysql.conf.d/mysqld.cnf $ service mysql restart //重启Mysql$ mysql -u root -p mysql&gt; show binary logs;1381 - You are not using binary loggingmysql&gt; show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000001 | 154 |+------------------+-----------+1 row in set (0.15 sec)mysql&gt; show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000001 | 154 |+------------------+-----------+1 row in set (0.03 sec)mysql&gt; delete from t_iost_2019_04; //开启binlog后删除数据库一张表的数据Query OK, 13244 rows affected (0.30 sec)mysql&gt; show master status; //查看目前的binlog文件+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 2006168 | dapp | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.04 sec)首先我们安装binlog2sql：$ git clone https://github.com/danfengcao/binlog2sql.git &amp;&amp; cd binlog2sql$ pip install -r requirements.txt$ cd binlog2sql$ ls -lhttotal 64Kdrwxr-xr-x 2 root root 4.0K Aug 29 17:50 binlog2sqldrwxr-xr-x 2 root root 4.0K Aug 29 17:50 example-rw-r--r-- 1 root root 35K Aug 29 17:50 LICENSE-rw-r--r-- 1 root root 9.3K Aug 29 17:50 README.md-rw-r--r-- 1 root root 54 Aug 29 17:50 requirements.txtdrwxr-xr-x 2 root root 4.0K Aug 29 17:50 tests$ pip install -r requirements.txt$ python binlog2sql/binlog2sql.py -h 127.0.0.1 -P 3306 -u admin -p&apos;admin&apos; -dtest -tuser --start-file=&apos;mysql-bin.000001&apos; --start-datetime=&apos;2019-08-26 00:00:00&apos; --stop-datetime=&apos;2019-08-26 18:00:00&apos; &gt; /tmp/raw.sql ##大致范围查找$ python binlog2sql/binlog2sql.py -h127.0.0.1 -P3306 -uadmin -p&apos;admin&apos; -dtest -tuser --start-file=&apos;mysql-bin.000054&apos; --start-position=257427 --stop-position=504272 -B &gt; /tmp/rollback.sql #找到要恢复sql的起始位置#命令解释： h 数据库ip p 数据库端口 u 账号 p 密码 d 目标库 t 表明 start-file binlog文件名 start-datetime 开始时间 stop-datetime 结束时间 &gt; 输出到指定文件 start-position 开始位置 stop-position 结束位置 B生成回滚sql$ mysql -h 127.0.0.1 -P 3306 -u admin &lt; /tmp/rollback.sql //执行回滚SQL数据的恢复mysql&gt; select count(*) from t_iost_2019_04; #查询恢复结果+----------+| count(*) |+----------+| 13244 |+----------+1 row in set (0.17 sec)]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 安装]]></title>
    <url>%2F2019%2F08%2F22%2FNginx%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Nginx下载地址 apt安装1$ apt-get install nginx 123456789101112131415/usr/sbin/nginx ： 主程序位置/etc/nginx：nginx文件配置/usr/share/nginx：存放静态文件/var/log/nginx：存放日志/etc/init.d/nginx start 启动Nginx/etc/init.d/nginx restart 重启Nginx service nginx status Nginx状态 service nginx restart 重启Nginx 源码安装安装gcc g++的依赖库12$ apt-get install build-essential$ apt-get install libtool 复制代码安装 pcre依赖库12$ apt-get update$ apt-get install libpcre3 libpcre3-dev zlib依赖库 ssl依赖库123$ apt-get install zlib1g-dev$ apt-get install openssl 安装nginx1234567891011121314151617181920#下载最新版本：wget http://nginx.org/download/nginx-1.11.3.tar.gz#解压：tar -zxvf nginx-1.11.3.tar.gz#进入解压目录：cd nginx-1.11.3#配置：./configure --prefix=/usr/local/nginx #编辑nginx：make注意：这里可能会报错，提示“pcre.h No such file or directory”,具体详见：http://stackoverflow.com/questions/22555561/error-building-fatal-error-pcre-h-no-such-file-or-directory需要安装 libpcre3-dev,命令为：sudo apt-get install libpcre3-dev#安装nginx：sudo make install#启动nginx：sudo /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf注意：-c 指定配置文件的路径，不加的话，nginx会自动加载默认路径的配置文件，可以通过 -h查看帮助命令。#查看nginx进程：ps -ef|grep nginx 基本命令123$ ./sbin/nginx -s reload #重新加载配置$ ./sbin/nginx -s stop #停止Nginx$ /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf #启动 安装Nginx脚本12345678910111213141516171819202122sudo apt-get install -y build-essentialpath=$(pwd)echo &quot;Download nginx....&quot; wget http://nginx.org/download/nginx-1.14.2.tar.gz tar -zxvf nginx-1.14.2.tar.gzecho &quot;Download openssl&quot; wget https://www.openssl.org/source/openssl-1.0.2r.tar.gz tar -zxf openssl-1.0.2r.tar.gzecho &quot;Download pcre&quot; wget https://ftp.pcre.org/pub/pcre/pcre-8.42.tar.gz tar -zxf pcre-8.42.tar.gz cd pcre-8.42/ ./configure &amp;&amp; make &amp;&amp;make install cd ..echo &quot;Download zlib&quot; wget http://zlib.net/zlib-1.2.11.tar.gz tar -zxf zlib-1.2.11.tar.gz cd zlib-1.2.11/ ./configure &amp;&amp; make &amp;&amp; make install cd ..echo &quot;编译 nginx...&quot;cd nginx-1.14.2/ &amp;&amp; ./configure --prefix=$path/nginx --with-pcre=$path/pcre-8.42/ --with-zlib=$path/zlib-1.2.11/ --with-http_ssl_module --with-openssl=$path/openssl-1.0.2r/ --with-stream --with-stream_ssl_module --with-http_v2_module --with-threads &amp;&amp; make &amp;&amp; make install 配置文件详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269... #全局块events&#123; #events 块 ...&#125;http&#123; #http 块 ... #http 全局块 server&#123; #server 块 ... #server 全局块 location [PATTERN]&#123; #location 块 ... &#125; location [PATTERN]&#123; #location 块 ... &#125; &#125; server&#123; #server 块 ... &#125; ... #http 全局块&#125; 1.全局块 全局块是默认配置文件从开始到events块之间的一部分内容，主要设置一些影响Nginx服务器整体运行的配置指令，因此，这些指令的作用域是Nginx服务器全局。 通常包括配置运行Nginx 服务器的用户（组）、允许生成的worker process数、Nginx 进程 PID存放路径、日志的存放路径和类型以及配置文件引入等。 2.events 块 events 块涉及的指令主要影响Nginx 服务器与用户的网络连接。常用到的设置包括是否开启对多worker process下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型处理连接请求，每个 worker process可以同时支持的最大连接数等。 这一部分指令对 Nginx服务器的性能影响较大，在实际配置中应该根据实际情况灵活调整。 3.http 块 http块是Nginx 服务器配置中的重要部分，代理、缓存和日志定义等绝大多数的功能和第三方模块的配置都可以放在这个模块。可以在 http全局块中配置的指令包括文件引入、MIME-Type定义、日志自定义、是否使用sendfile传输文件、连接超时时间、单连接q 请求数上限等。 4.server 块 server 块和“虚拟主机”的概念有密切联系。在 server 全局块中，最常见的两个配置项是本虚拟主机的监听配置和本虚拟主机的名称或 IP 配置。 5.location 块 location 块的主要作用是，基于Nginx服务器接受到的q 请求字符串，对除虚拟主机名称之外的字符串j 进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能都是在这部分实现。许多第三方模块的配置也是在location块中提供功能。#普通配置#==性能配置#运行用户user nobody;#pid文件pid logs/nginx.pid;#Nginx基于事件的非阻塞多路复用模型（epoll或kquene）#一个进程在短时间内可以响应大量请求，工作进程设置与cpu数相同，避免cpu在多个进程间切换增加开销#==worker进程数，通常设置&lt;=CPU数量，auto为自动检测，一般设置最大8个即可，再大性能提升较小或不稳定worker_processes auto;#==将每个进程绑定到特定cpu上，避免进程在cpu间切换的开销worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;#==worker进程打开最大文件数，可CPU*10000设置，或设置系统最大数量655350worker_rlimit_nofile 102400;#全局错误日志error_log logs/error.log;#events模块中包含nginx中所有处理连接的设置，并发响应能力的关键配置events &#123; #==每个进程同时打开的最大连接数（最大并发数） worker_connections 102400; #==告诉nginx收到一个新链接通知后接受尽可能多的链接 #multi_accept on; #一般http 1.1协议下，浏览器默认使用两个并发链接 #如果是反向代理，nginx需要和客户端保持连接，还需要和后端服务器保持连接 #Http服务器时，设置max_client=worker_processes*worker_connections/2 #反向代理时，设置max_client=worker_processes*worker_connections/4 #==最大可用客户端数 #max_client #==使用非阻塞模型，设置复用客户端线程的轮训方法 use epoll;&#125;#http模块控制着nginx http处理的所有核心特性http &#123; #打开或关闭错误页面中的nginx版本号等信息 server_tokens on; #!server_tag on; #!server_info on; #==优化磁盘IO设置，指定nginx是否调用sendfile函数来输出文件，普通应用设为on，下载等磁盘IO高的应用，可设为off sendfile on; #缓存发送请求，启用如下两个配置，会在数据包达到一定大小后再发送数据 #这样会减少网络通信次数，降低阻塞概率，但也会影响响应的及时性 #比较适合于文件下载这类的大数据包通信场景 #tcp_nopush on; #tcp_nodelay on; #==设置nginx是否存储访问日志，关闭这个可以让读取磁盘IO操作更快 access_log on; #设置nginx只记录严重错误，可减少IO压力 #error_log logs/error.log crit; #Http1.1支持长连接 #降低每个链接的alive时间可在一定程度上提高响应连接数量 #==给客户端分配keep-alive链接超时时间 keepalive_timeout 30; #设置用户保存各种key的共享内存的参数，5m指的是5兆 limit_conn_zone $binary_remote_addr zone=addr:5m; #为给定的key设置最大的连接数，这里的key是addr，设定的值是100，就是说允许每一个IP地址最多同时打开100个连接 limit_conn addr 100; #include指在当前文件中包含另一个文件内容 include mime.types; #设置文件使用默认的mine-type default_type text/html; #设置默认字符集 charset UTF-8; #==设置nginx采用gzip压缩的形式发送数据，减少发送数据量，但会增加请求处理时间及CPU处理时间，需要权衡 gzip on; #==加vary给代理服务器使用，针对有的浏览器支持压缩，有个不支持，根据客户端的HTTP头来判断是否需要压缩 gzip_vary on; #nginx在压缩资源之前，先查找是否有预先gzip处理过的资源 #!gzip_static on; #为指定的客户端禁用gzip功能 gzip_disable &quot;MSIE[1-6]\.&quot;; #允许或禁止压缩基于请求和相应的响应流，any代表压缩所有请求 gzip_proxied any; #==启用压缩的最少字节数，如果请求小于1024字节则不压缩，压缩过程会消耗系统资源 gzip_min_length 1024; #==数据压缩等级，1-9之间，9最慢压缩比最大，压缩比越大对系统性能要求越高 gzip_comp_level 2; #需要压缩的数据格式 gzip_types text/plain text/css text/xml text/javascript application/json application/x-javascript application/xml application/xml+rss; #静态文件缓存 #==开启缓存的同时也指定了缓存文件的最大数量，20s如果文件没有被请求则删除缓存 open_file_cache max=100000 inactive=20s; #==多长时间检查一次缓存的有效期 open_file_cache_valid 30s; #==有效期内缓存文件最小的访问次数，只有访问超过2次的才会被缓存 open_file_cache_min_uses 2; #当搜索一个文件时是否缓存错误信息 open_file_cache_errors on; #==允许客户端请求的最大单文件字节数 client_max_body_size 4m; #==客户端请求头缓冲区大小 client_header_buffer_size 4k; #是否启用对发送给客户端的URL进行修改 proxy_redirect off; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #==nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 60; #==连接成功后，后端服务器响应时间(代理接收超时) proxy_read_timeout 120; #==后端服务器数据回传时间(代理发送超时) proxy_send_timeout 20; #==设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffer_size 32k; #==proxy_buffers缓冲区，网页平均在32k以下的设置 proxy_buffers 4 128k; #==高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 256k; #==设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 256k; #==1G内存缓冲空间，3天不用删除，最大磁盘缓冲空间2G proxy_cache_path /home/cache levels=1:2 keys_zone=cache_one:1024m inactive=3d max_size=2g; #设定负载均衡服务器列表 upstream nginx.test.com&#123; #后端服务器访问规则 #ip_hash; #weight参数表示权重值，权值越高被分配到的几率越大 #server 10.11.12.116:80 weight=5; #PC_Local server 10.11.12.116:80; #PC_Server server 10.11.12.112:80; #Notebook #server 10.11.12.106:80; &#125; #server代表虚拟主机，可以理解为站点（挂载多个站点，只需要配置多个server及upstream节点即可） server &#123; #监听80端口 listen 80; #识别的域名，定义使用nginx.test.com访问 server_name nginx.test.com; #设定本虚拟主机的访问日志 access_log logs/nginx.test.com.access.log; #一个域名下匹配多个URI的访问，使用location进行区分，后面紧跟着的/代表匹配规则 #如动态资源访问和静态资源访问会分别指向不同的位置的应用场景 # # 基本语法规则：location [=|~|~*|^~] /uri/ &#123;...&#125; # = 开头表示精确匹配 # ^~ 开头表示uri以某个常规字符串开头，匹配成功后不再进行正则匹配 # ~ 开头表示区分大小写的正则匹配 # ~* 开头表示不区分大小写的正则匹配 # !~ 开头表示区分大小写的不匹配的正则 # !~* 开头表示不区分大小写的不匹配的正则 # / 通用匹配，任何请求都会被匹配到 # # 理解如下： # 有两种匹配模式：普通字符串匹配，正则匹配 # 无开头引导字符或以=开头表示普通字符串匹配 # 以~或~*开头表示正则匹配，~*表示不区分大小写 # 【多个location时，先匹配普通字符串location，再匹配正则location】 # 只识别URI部分，例如请求为“/test/1/abc.do?arg=xxx” # （1）先查找是否有=开头的精确匹配，即“location=/test/1/abc.do &#123;...&#125;” # （2）再查找普通匹配，以“最大前缀”为规则，如有以下两个location # location /test/ &#123;...&#125; # location /test/1/ &#123;...&#125; # 则匹配后一项 # （3）匹配到一个普通location后，搜索并未结束，而是暂存当前结果，并继续进行正则搜索 # （4）在所有正则location中找到第一个匹配项后，以此匹配项为最终结果 # 【所以正则匹配项，匹配规则受定义前后顺序影响，但普通匹配不会】 # （5）如果未找到正则匹配项，则以（3）中缓存的结果为最终结果 # （6）如果一个匹配都没有，则返回404 # location =/ &#123;...&#125;与location / &#123;...&#125;的差别 # 前一个是精确匹配，只响应“/”的请求，所有“/xxx”形式的请求不会以“前缀匹配形式”匹配到它 # 后一个正相反，所有请求必然都是以“/”开头，所以没有其他匹配结果时一定会执行到它 # location ^~ / &#123;...&#125; ^~的意思是禁止正则匹配，表示匹配到此项后不再进行后续的正则搜索 # 相当于普通匹配模式匹配成功后就以此结果为最终结果，停止进行后续的正则匹配 location / &#123; #定义服务器的默认网站根目录位置，可以写相对路径，也可以写绝对路径 root html; #定义首页索引文件的名称 index index.html index.htm; #定义转发后端负载服务器组 proxy_pass http://nginx.test.com; &#125; #定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/&#123; root /var/www/virtual/htdocs; #过期时间1天 expires 1d; #关闭媒体文件日志 access_log off; log_not_found off; &#125; #设定查看Nginx状态的地址 location /NginxStatus &#123; #!stub_status on; #无此关键字 access_log off; auth_basic &quot;NginxStatus&quot;; auth_basic_user_file conf/htpasswd; &#125; #禁止访问的文件.htxxx location ~ /\.ht &#123; #deny all;禁止访问，返回403 deny all; #allow all;允许访问 &#125; &#125; #网站较多的情况下ngxin又不会请求瓶颈可以考虑挂多个站点，并把虚拟主机配置单独放在一个文件内，引入进来 #include website.conf;&#125;]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux时区更改]]></title>
    <url>%2F2019%2F07%2F18%2FLinux%E6%97%B6%E5%8C%BA%E6%9B%B4%E6%94%B9%2F</url>
    <content type="text"><![CDATA[时区查看123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475761.tzselect命令无法修改时区，仅给出时区的城市表示法2.TZ变量和/etc/localtime文件会影响时区，并建议直接修改/etc/localtime文件3.如果在shell中临时需要变更时区信息，可以修改TZ变量实现。4.在profile文件里设置变量TZ，达到和修改/etc/localtime类似的效果。$ tzselectPlease identify a location so that time zone rules can be set correctly.Please select a continent, ocean, &quot;coord&quot;, or &quot;TZ&quot;. 1) Africa 2) Americas 3) Antarctica 4) Asia 5) Atlantic Ocean 6) Australia 7) Europe 8) Indian Ocean 9) Pacific Ocean10) coord - I want to use geographical coordinates.11) TZ - I want to specify the time zone using the Posix TZ format.#? 4Please select a country whose clocks agree with yours. 1) Afghanistan 18) Israel 35) Palestine 2) Armenia 19) Japan 36) Philippines 3) Azerbaijan 20) Jordan 37) Qatar 4) Bahrain 21) Kazakhstan 38) Russia 5) Bangladesh 22) Korea (North) 39) Saudi Arabia 6) Bhutan 23) Korea (South) 40) Singapore 7) Brunei 24) Kuwait 41) Sri Lanka 8) Cambodia 25) Kyrgyzstan 42) Syria 9) China 26) Laos 43) Taiwan10) Cyprus 27) Lebanon 44) Tajikistan11) East Timor 28) Macau 45) Thailand12) Georgia 29) Malaysia 46) Turkmenistan13) Hong Kong 30) Mongolia 47) United Arab Emirates14) India 31) Myanmar (Burma) 48) Uzbekistan15) Indonesia 32) Nepal 49) Vietnam16) Iran 33) Oman 50) Yemen17) Iraq 34) Pakistan#? 9Please select one of the following time zone regions.1) Beijing Time2) Xinjiang Time#? 1The following information has been given: China Beijing TimeTherefore TZ=&apos;Asia/Shanghai&apos; will be used.Local time is now: Thu Jul 18 15:54:50 CST 2019.Universal Time is now: Thu Jul 18 07:54:50 UTC 2019.Is the above information OK?1) Yes2) No#? yesPlease enter a number in range.#? yesPlease enter a number in range.#? 1You can make this change permanent for yourself by appending the line TZ=&apos;Asia/Shanghai&apos;; export TZto the file &apos;.profile&apos; in your home directory; then log out and log in again.Here is that TZ value again, this time on standard output so that youcan use the /usr/bin/tzselect command in shell scripts:Asia/Shanghaicurl http://ifconfig.me 12345678910111213141516171819202122232425262728293031323334353637$ cat /etc/profile //在文件末尾追加时区 export TZ=Asia/Shanghai # /etc/profile: system-wide .profile file for the Bourne shell (sh(1))# and Bourne compatible shells (bash(1), ksh(1), ash(1), ...).if [ &quot;$PS1&quot; ]; then if [ &quot;$BASH&quot; ] &amp;&amp; [ &quot;$BASH&quot; != &quot;/bin/sh&quot; ]; then # The file bash.bashrc already sets the default PS1. # PS1=&apos;\h:\w\$ &apos; if [ -f /etc/bash.bashrc ]; then . /etc/bash.bashrc fi else if [ &quot;`id -u`&quot; -eq 0 ]; then PS1=&apos;# &apos; else PS1=&apos;$ &apos; fi fifiif [ -d /etc/profile.d ]; then for i in /etc/profile.d/*.sh; do if [ -r $i ]; then . $i fi done unset ifiexport JAVA_HOME=/usr/local/java/jdk1.8.0_211export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib:$CLASSPATHexport JAVA_PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;JRE_HOME&#125;/binexport PATH=$PATH:$&#123;JAVA_PATH&#125;export TZ=Asia/Shanghai $ source /etc/profile //生效文件]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建简单的文件下载服务器]]></title>
    <url>%2F2019%2F06%2F18%2F%E6%90%AD%E5%BB%BA%E7%AE%80%E5%8D%95%E7%9A%84%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[[apache2]123456789$ root@user: apt-getinstall apache2 //配置文件地址 /etc/apache2/sites-enabled/000-default$ root@user: cd /var/www/html/ //并在此目录放入要下载的文件$ root@user: rm -f index.html //删除该文件$ root@user: curl cip.cc //获取服务器外网IP 通过浏览器访问 如图 $ root@user: /etc/init.d/apache2 restart //重启Apache2 $ root@user: /etc/init.d/apache2 stop //停止Apache2 [Nginx]12345678910111213141516171819202122232425262728293031323334353637$ root@user: apt-getinstall nginx //配置文件地址 /etc/nginx/nginx.conf 在nginx.conf末尾有一句：include /etc/nginx/conf.d/*.conf; 推荐把用户自己的配置放到conf.d/$ root@user: vim /etc/nginx/conf.d/default.conf //添加用户的自定义配置文件 autoindex on;# 显示目录 autoindex_exact_size on;# 显示文件大小 autoindex_localtime on;# 显示文件时间$ root@user: vim /etc/nginx/nginx.conf //在http 增加以下配置 server &#123; listen 8080 default_server; listen [::]:8080 default_server; server_name _; root /root/share/; //分项目录 # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125;$ root@user: /etc/init.d/nginx reload 重新加载$ root@user: curl cip.cc //获取服务器外网IP 通过浏览器访问 如图 错误日志 /var/log/nginx/error.log访问日志 /var/log/nginx/access.log]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 安装]]></title>
    <url>%2F2019%2F06%2F14%2FMysql%20%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344//下载mysql-apt-config_0.8.13-1_all.deb 到Linux $apt-get update $mkdir mysql$cd mysql//安装$apt-get install mysql-server//查看Mysql服务状态$ service mysql status//重启Mysql$service mysql restart//查看Mysql端口占用$netstat -tunlp | grep 3306//进行安装初始化设置密码等操作$ mysql_secure_installation//设置 Linux服务器数据库可以在任意服务器上远程连接$ mysql -u root -p mysql&gt; show databases;mysql&gt; use mysql;mysql&gt; select host, user from user;mysql&gt; update user set host = &apos;%&apos; where user = &apos;root&apos;;mysql&gt; flush privileges;mysql&gt; exit;从命令行终端运行此命令，将在寻找Linux/BSD / OS X系统中的MySQL配置文件 my.cnf 文件：mysql --help | grep &apos;Default options&apos; -A 1上面命令执行后，会有这样的输出：Default options are read from the following files in the given order:/etc/my.cnf /etc/mysql/my.cnf /usr/local/etc/my.cnf ~/.my.cnf/etc/mysql/mysql.conf.d mysql配置文件现在，可以检查你正在使用的 my.cnf 文件是否存在。在 Mac OS X 中默认式没有 my.cnf 文件的。你可以从这个地方复制一份过去 /usr/local/mysql/support-files/my-default.cnf 每个版本都不一样，你只需要找到一个 .cnf]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 系统搭建Redis]]></title>
    <url>%2F2019%2F06%2F13%2FLinux%20%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BARedis%2F</url>
    <content type="text"><![CDATA[Installation1234567891011121314151617181920212223$ mkdir redis //创建redis目录$ wget http://download.redis.io/releases/redis-5.0.5.tar.gz //下载安装包$ tar xzf redis-5.0.5.tar.gz //解压 $ cd redis-5.0.5 //进入redis-5.0.5目录 $ make //生成有效文件$ cd src $ ./redis-server //1.启动redis服务 这种方式启动redis 使用的是默认配置$ ./redis-cliredis&gt; set foo barOKredis&gt; get foo&quot;bar&quot;$ vim ../redis.conf //编辑Redis配置文件$ ./redis-server ../redis.conf //2.使用指定配置文件使用下面命令启动 redis 配置文件详解 fields desc daemonize no 默认情况下，redis不是在后台运行的，如果需要在后台运行，把该项的值更改为yes port 指定redis运行的端口，默认是6379 bind 指定redis只接收来自于该IP地址的请求，如果不进行设置，那么将处理所有请求，在生产环境中最好设置该项 timeout 设置客户端连接时的超时时间，单位为秒。当客户端在这段时间内没有发出任何指令，那么关闭该连接 0是关闭此设置 loglevel # debu 记录很多信息，用于开发和测试 varbose 有用的信息，不像debug会记录那么多 notice 普通的verbose，常用于生产环境 warning 只有非常重要或者严重的信息会记录到日志 logfile /var/log/redis/redis.log 配置log文件地址 默认值为stdout，标准输出，若后台模式会输出到/dev/null rdbcompression yes 存储至本地数据库时（持久化到rdb文件）是否压缩数据，默认为yes dbfilename dump.rdb 本地持久化数据库文件名，默认值为dump.rdb requirepass foobared 设置客户端连接后进行任何其他指定前需要使用的密码。 save 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 save 900 1 900秒（15分钟）内有1个更改 windows Redis Desktop Manager 连接不上Redis的问题1231. ufw status 查看Redis 6379 端口是否开启 未开启则 ：ufw allow 6379(Redis默认端口 修改默认端口到redis.conf修改)2. 云平台安全组是否开启了Redis 6379 端口]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见问题汇总]]></title>
    <url>%2F2019%2F06%2F13%2F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[Linuxcmmand redis-cli not found123456789root@wrecked:~# redis-cli -h 127.0.0.1 -p 6379 -a 123456Command &apos;redis-cli&apos; not found解决办法：cp /home/redis/redis-2.8.17/src/redis-cli /usr/local/bin/ 拷贝redis-cli 到 /usr/local/bin/ `/usr/bin`下面的都是系统预装的可执行程序，会随着系统升级而改变。`/usr/local/bin`目录是给用户放置自己的可执行程序的地方，推荐放在这里，不会被系统升级而覆盖同名文件。 buntu防火墙的开启，关闭，端口的打开，查看1234567891011121314151.防火墙的打开$ ufw enable2.防火墙的重启$ ufw reload3.打开想要的端口（以9000为例）$ ufw allow 90004.查看本机端口使用情况$ ufw status]]></content>
      <categories>
        <category>问题</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统配置]]></title>
    <url>%2F2019%2F06%2F11%2FLinux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[基础概念 物理CPU：物理CPU就是插在主机上的真实的CPU硬件，在Linux下可以数不同的physical id 来确认主机的物理CPU个数。 核心数：物理CPU下一层概念就是核心数，我们常常会听说多核处理器，其中的核指的就是核心数。在Linux下可以通过cores来确认主机的物理CPU的核心数。 逻辑CPU：核心数下一层的概念是逻辑CPU，逻辑CPU跟超线程技术有联系，假如物理CPU不支持超线程的，那么逻辑CPU的数量等于核心数的数量； 如果物理CPU支持超线程，那么逻辑CPU的数目是核心数数目的两倍。在Linux下可以通过 processors 的数目来确认逻辑CPU的数量。 超线程：超线程是英特尔开发出来的一项技术，使得单个处理器可以象两个逻辑处理器那样运行，这样单个处理器以并行执行线程。 这里的单个处理器也可以理解为CPU的一个核心；这样便可以理解为什么开启了超线程技术后，逻辑CPU的数目是核心数的两倍了。 查看物理CPU数量1cat /proc/cpuinfo | grep &apos;physical id&apos; | uniq |wc -l 查看核心数1cat /proc/cpuinfo | grep &apos;core id&apos; | uniq |wc -l 查看逻辑CPU数目123top命令中看到的CPU数目是逻辑CPU（输入top后再按1）。cat /proc/cpuinfo | grep &apos;processor&apos; | wc -l 查看内存大小 硬盘大小12cat /proc/meminfo |grep MemTotal //内存大小fdisk -l |grep Disk //硬盘大小]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客基本配置]]></title>
    <url>%2F2019%2F06%2F04%2F%E5%8D%9A%E5%AE%A2%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[环境初始化1234567891011121314151617npm install hexo-cli -g //安装hexo modulesmkdir WreckedBolg //创建目录 cd WreckedBolg //进入目录 hexo init //初始化目录npm install hexo-deployer-git --save 安装部署gitHub依赖git clone https://github.com/theme-next/hexo-theme-next themes/next //主题文件地址npm install hexo-generator-searchdb --save //搜素引擎依赖包 npm install hexo-related-popular-posts --save //相关文章包 Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server //生成本地Service http://localhost:4000/ 访问地址 hexo s 简写 More info: Server Generate static files1$ hexo generate //生成静态HTML hexo g 简写 More info: Generating Deploy to remote sites1$ hexo deploy //部署到GitHub hexo d 简写 More info: Deployment 配置文件 _config.yml1234deploy: type: git repo: https://github.com/***/***.github.io.git branch: master 常用命令1234567891011hexo g #完整命令为hexo generate,用于生成静态文件hexo s #完整命令为hexo server,用于启动服务器，主要用来本地预览hexo d #完整命令为hexo deploy,用于将本地文件发布到github等git仓库上hexo n “my article” #完整命令为hexo new,用于新建一篇名为“my article”的文章hexo n “我的第一篇文章”hexo list page / post / route / tag / category(参数) 查看博客对应信息 背景图设置123..\themes\next\layout\_layout.swig 目录 找到&lt;Body&gt;标签 设置背景图片 style=&quot;background: url(https://raw.githubusercontent.com/zhangChaoWrecked/pictures/master/Background.jpg) no-repeat fixed ;&quot; 点击跳转配置教程链接]]></content>
  </entry>
  <entry>
    <title><![CDATA[如何在一台电脑使用GitHub GitLab进行项目维护]]></title>
    <url>%2F2019%2F06%2F04%2F%E5%A6%82%E4%BD%95%E5%9C%A8%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91%E4%BD%BF%E7%94%A8GitHub%20GitLab%E8%BF%9B%E8%A1%8C%E9%A1%B9%E7%9B%AE%E7%BB%B4%E6%8A%A4%2F</url>
    <content type="text"><![CDATA[1.生成SSH Key123在 C:\Users\用户名\.ssh 目录 鼠标右键 git bash ssh-keygen -t rsa -C &quot;****@qq.com&quot; //生成pub文件需指定生成文件名 id_rsa_hub/id_rsa_lab 区分GitHub/GitLabssh-keygen -t rsa -C &quot;****@163.com&quot; 2.配置Config123456789101112131415161718192021222324252627282930在 C:\Users\用户名\.ssh 目录 生成config文件 编辑如下：# self(****@qq.com)Host github(拉取代码时仓库的别名) Port 22 User git HostName github.com (github域名) PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa_hub (生成的GitHub公钥)# company(****@163.com)Host gitlab(拉取代码时仓库的别名) Port 端口(默认22) User git HostName ******* (公司GitLab域名) PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa_lab(生成的GitLab公钥) Host 作用[github为例]：#传统使用$git clone git@github.com:zhangChaoWrecked/pictures.git$git remote add origin git@github.com:zhangChaoWrecked/pictures.git#配置Config之后使用(host也可配置为域名即:github.com) $git clone git@[Host]:zhangChaoWrecked/pictures.git$git remote add origin git@[Host]:zhangChaoWrecked/pictures.git 生成文件如下图： 配置Hosts 加速 拉取代码速度12151.101.185.194 github.global.ssl.fastly.net192.30.253.112 github.com 3.测试关联12ssh -T git@githubssh -T git@gitlab 4.拉取远程代码或下载到本地12345678910#取消全局 用户名/邮箱 配置(可跳过)$git config --global --unset user.name$git config --global --unset user.email$cd 项目名$git init$git config --local user.name &quot;用户名&quot;$git config --local user.email &quot;邮箱&quot;$git remote add origin git@[host]:***/***.git(git remote rm origin 删除之前关联的origin)$git pull orgin master]]></content>
      <tags>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Volatile]]></title>
    <url>%2F2019%2F02%2F22%2FVolatile%2F</url>
    <content type="text"><![CDATA[上下文切换 阐述：CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换 如何减少上下文切换 方案 无锁并发编程 将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据 CAS算法 Java的Atomic包使用CAS算法来更新数据，而不需要加锁 使用最少线程 避免创建不需要的线程 volatile 描述 特点 1.使用volatile关键字会强制将修改的值立即写入主存 1.保证有序性、可见性 2.导致其他线程的工作内存中缓存变量的缓存行无效 2.不保证原子性 1应用场景：状态标志]]></content>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ安装]]></title>
    <url>%2F2019%2F01%2F19%2FRabbitMQ%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[erlang下载 rabbit下载 cmd命令行12345&quot;E:\rabbitMq\rabbitmq_server-3.7.10\sbin\rabbitmq-plugins.bat&quot; enable rabbitmq_management 开启web管理接口 net stop RabbitMQ &amp;&amp; net start RabbitMQ 重启rabbitMQrabbitmqctl.bat list_users 列出当前用户列表 账号 密码 guest(默认) guest(默认) 本地浏览器打开 Linux安装12345678910111213141516$ apt-get install erlang$ apt-get install rabbitmq-server$ service rabbitmq-server status //service rabbitmq-server status$ service rabbitmq-server stop //停止$ service rabbitmq-server start //启动$ vim /etc/rabbitmq/rabbitmq.config //设置guest可以远程访问[&#123;rabbit, [&#123;loopback_users, []&#125;]&#125;].$ service rabbitmq-server restart //重启 $ /usr/sbin/rabbitmq-plugins enable rabbitmq_management //安装客户端管理插件 开启Web管理页面 http://ip:15672 使用guest,guest 进行登陆web页面了]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java DES(对称加密)]]></title>
    <url>%2F2019%2F01%2F16%2FJava%20Crypto(%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86)%2F</url>
    <content type="text"><![CDATA[简单一种对称加密与解密123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104import javax.crypto.Cipher;import javax.crypto.KeyGenerator;import javax.crypto.SecretKey;import javax.crypto.spec.SecretKeySpec;public class DESUtils &#123; /* * 生成密钥 */ public static byte[] initKey() throws Exception &#123; KeyGenerator keyGen = KeyGenerator.getInstance("DES"); keyGen.init(56); SecretKey secretKey = keyGen.generateKey(); return secretKey.getEncoded(); &#125; /* * DES 加密 */ public static String encrypt(byte[] data, byte[] key) throws Exception &#123; SecretKey secretKey = new SecretKeySpec(key, "DES"); Cipher cipher = Cipher.getInstance("DES"); cipher.init(Cipher.ENCRYPT_MODE, secretKey); byte[] cipherBytes = cipher.doFinal(data); String result = byte2Hex(cipherBytes); return result; &#125; /* * DES 解密 */ public static String decrypt(byte[] data, byte[] key) throws Exception &#123; SecretKey secretKey = new SecretKeySpec(key, "DES"); Cipher cipher = Cipher.getInstance("DES"); cipher.init(Cipher.DECRYPT_MODE, secretKey); byte[] plainBytes = cipher.doFinal(data); String result = new String(plainBytes); return result; &#125; private static int toByte(char c) &#123; byte b = (byte) "0123456789ABCDEF".indexOf(c); return b; &#125; public static byte[] hexToByte(String hex) &#123; int len = (hex.length() / 2); byte[] result = new byte[len]; char[] achar = hex.toCharArray(); for (int i = 0; i &lt; len; i++) &#123; int pos = i * 2; result[i] = (byte) (toByte(achar[pos]) &lt;&lt; 4 | toByte(achar[pos + 1])); &#125; return result; &#125; public static String byte2Hex(byte[] b) &#123; String stmp = ""; StringBuilder sb = new StringBuilder(""); for (int n = 0; n &lt; b.length; n++) &#123; stmp = Integer.toHexString(b[n] &amp; 0xFF); sb.append((stmp.length() == 1) ? "0" + stmp : stmp); &#125; return sb.toString().toUpperCase().trim(); &#125; //加密 public static String encryptStr(String str, String secreytKey) throws Exception &#123; String enResult = encrypt(str.getBytes(), hexToByte(secreytKey)); return enResult; &#125; //解密 public static String decryptStr(String str, String secreytKey) throws Exception &#123; String deResult = decrypt(hexToByte(str), hexToByte(secreytKey)); return deResult; &#125; /*** * 秘钥769bfbae9d20100d 加密结果e3f6b60180661bb0d541de00260afb10 解密结果hello_world * * @param args * @throws Exception */ public static void main(String[] args) throws Exception &#123; //生成秘钥 byte[] desKey = initKey(); String secreytKey = byte2Hex(desKey); System.out.println("秘钥" + secreytKey.toLowerCase()); //加密 String hello_world = encryptStr("hello_world", secreytKey); System.out.println("加密结果" + hello_world.toLowerCase()); //解密 String deResult = decryptStr(hello_world, secreytKey); System.out.println("解密结果" + deResult); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Crypto</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal]]></title>
    <url>%2F2018%2F12%2F04%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[ThreadLocal 类结构图 get12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; set12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; remove12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125; setInitialValue12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; &#125; initialValue123protected T initialValue() &#123; return null;&#125; getMap123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; createMap123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue); &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Top命令]]></title>
    <url>%2F2018%2F11%2F30%2FLinux%20Top%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[uptime / top116:36:50 up 108 days, 7:24, 2 users, load average: 61.27, 61.50, 61.60 Field Desc 16:36:50 时间 up 1:22 系统运行时间 users 当前登录用户数 load average 三个数值分别为 1分钟、5分钟、15分钟前到现在的平均负载 英文文档链接 Understanding-Load-Averages中文文档链接 Understanding-Load-AveragesTasks key value Desc 29 total 进程总数 1 running 正在运行的进程数 28 sleeping 睡眠的进程数 0 stopped 停止的进程数 0 zombie 僵尸进程数 Cpu(s) key value Desc 0.3% us 用户空间占用CPU百分比 1.0% sy 内核空间占用CPU百分比 0.0% ni 用户进程空间内改变过优先级的进程占用CPU百分比 98.7% id 空闲CPU百分比 0.0% wa 等待输入输出的CPU时间百分比 Mem key value Desc 191272k total 物理内存总量 173656k used 使用的物理内存总量 17616k free 空闲内存总量 22052k buffers 用作内核缓存的内存量 Swap key value Desc 192772k total 交换区总量 0k used 使用的交换区总量 192772k free 空闲交换区总量 123988k cached 缓冲的交换区总量。 详细信息 Key Desc PID 进程id PPID 父进程id RUSER Real user name UID 进程所有者的用户id USER 进程所有者的用户名 GROUP 进程所有者的组名 TTY 启动进程的终端名。不是从终端启动的进程则显示为 ? PR 优先级 NI nice值。负值表示高优先级，正值表示低优先级 P 最后使用的CPU，仅在多CPU环境下有意义 %CPU 上次更新到现在的CPU时间占用百分比 TIME 进程使用的CPU时间总计，单位秒 TIME+ 进程使用的CPU时间总计，单位1/100秒 %MEM 进程使用的物理内存百分比 VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。 RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA CODE 可执行代码占用的物理内存大小，单位kb DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb SHR 共享内存大小，单位kb nFLT 页面错误次数 nDRT 最后一次写入到现在，被修改过的页面数。 S 进程状态。 S D=不可中断的睡眠状态 S R=运行 S S=睡眠 S T=跟踪/停止 S Z=僵尸进程 COMMAND 命令名/命令行 WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名 Flags 任务标志，参考 sched.h]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Info命令详解]]></title>
    <url>%2F2018%2F11%2F29%2FRedis%20Info%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Redis 内存使用率Memory1info memory //Redis命令 Field Value Description used_memory 3228479928 used_memory_human 3.01G redis已经使用内存 used_memory_rss 5631479808 used_memory_rss_human 5.24G 从操作系统的角度，返回 Redis 已分配的内存总量(俗称常驻集大小) used_memory_peak 10753524688 used_memory_peak_human 10.02G 曾经占用内存的峰值 used_memory_peak_perc 30.02% (used_memory/ used_memory_peak) *100% used_memory_overhead 207532802 Redis为了维护数据集的内部机制所需的内存开销 used_memory_startup 6144240 Redis服务器启动时消耗的内存 used_memory_dataset 3020947126 used_memory—used_memory_overhead used_memory_dataset_perc 93.75% 100%*(used_memory_dataset/(used_memory—used_memory_startup)) total_system_memory 33738252288 total_system_memory_human 31.42G 服务器本身的内存大小 used_memory_lua 51200 used_memory_lua_human 50.00K Lua 引擎所使用的内存大小 maxmemory 10737418240 maxmemory_human 10.00G 服务器设定的redis可以使用的最大内存 maxmemory_policy noeviction 当达到maxmemory时的淘汰策略 mem_fragmentation_ratio 1.74 碎片率意味着74%的内存浪费 mem_allocator jemalloc-4.0.3 内存分配器 active_defrag_running 0 lazyfree_pending_objects 0 maxmemory_policy 选择策略 Fields Description noeviction 默认策略，不淘汰，如果内存已满，添加数据是报错。 allkeys-lru 在所有键中，选取最近最少使用的数据抛弃。 volatile-lru 在设置了过期时间的所有键中，选取最近最少使用的数据抛弃。 allkeys-random 在所有键中，随机抛弃 volatile-random 在设置了过期时间的所有键，随机抛弃 volatile-ttl 在设置了过期时间的所有键，抛弃存活时间最短的数据 Server1info server //Redis 命令 Fiels Value Description redis_version 4.0.9 Redis 服务器版本 redis_git_sha1 00000000 redis_git_dirty 0 redis_build_id 1981f57149260a90 redis_mode standalone 运行模式，单机或者集群 os Linux 4.4.0-105-generic x86_64 Redis 服务器的宿主操作系统 arch_bits 64 架构（32 或 64 位） multiplexing_api epoll Redis 所使用的事件处理机制 atomicvar_api atomic-builtin 原子处理api gcc_version 5.4.0 编译 Redis 时所使用的 GCC 版本 process_id 8004 服务器进程的 PID run_id 6a5182bea61558be39d072ab5fd14579f12fc271 Redis 服务器的随机标识符（用于 Sentinel 和集群） tcp_port 6379 监听端口 uptime_in_seconds 1406431 自 Redis 服务器启动以来，经过的秒数 uptime_in_days 16 自 Redis 服务器启动以来，经过的天数 hz 10 lru_clock 16752391 以分钟为单位进行自增的时钟，用于 LRU 管理 executable /home/lianxiang/redis/redis-4.0.9/src/redis-server 执行文件地址 config_file /home/redis/redis.conf 配置文件地址 Clients1info clients //Redis 命令 Fiels Value Description connected_clients 11721 已连接客户端的数量（不包括通过从属服务器连接的客户端） client_longest_output_list 0 当前连接的客户端当中，最长的输出列表 client_biggest_input_buf 18 当前连接的客户端当中，最大输入缓存 blocked_clients 0 正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量 Commandstats1info commandstats //Redis 命令 Fiels Value Description cmdstat_cluster calls=77,usec=117,usec_per_call=1.52 使用次数/总时间(微秒数)/平均时间 cmdstat_zremrangebyscore calls=402280989,usec=3007286205,usec_per_call=7.48 … cmdstat_script calls=31,usec=533,usec_per_call=17.19 … cmdstat_evalsha calls=58716,usec=7416675,usec_per_call=126.31 … cmdstat_smembers calls=1031965,usec=25706632,usec_per_call=24.91 … cmdstat_sscan calls=15,usec=1026,usec_per_call=68.40 … cmdstat_hkeys calls=294,usec=211364,usec_per_call=718.93 … cmdstat_expire calls=124221201,usec=292783944,usec_per_call=2.36 … cmdstat_zrangebyscore calls=37214253,usec=358725386,usec_per_call=9.64 … cmdstat_hmget calls=7,usec=38,usec_per_call=5.43 … cmdstat_zrevrange calls=9772,usec=98592,usec_per_call=10.09 … cmdstat_hget calls=21564966,usec=41137042,usec_per_call=1.91 … cmdstat_scan calls=47381,usec=26088568,usec_per_call=550.61 … … … … 慢查询日志1SlowLog Get 1 //获取一条 1SlowLog Len //慢日志数量 Fiels Value Description 1) “67227” 唯一性(unique)的日志标识符 2) “1543481885” 被记录命令的执行时间点，以 UNIX 时间戳格式表示 3) “10104” 查询执行时间，以微秒为单位 4.1) “ZADD” 执行的命令 4.2) PAIR_MARKET_DEPTH_SELL:4:3115” 完整的命令 4.3) “0.02638215” 参数 4.4) “[0.026382150000000000,101.470000000000000000]” 参数 4.5) “47.91.198.244:43484” IP+端口]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
</search>
