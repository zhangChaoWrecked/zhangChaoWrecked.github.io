<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux 安装Jenkins]]></title>
    <url>%2F2019%2F08%2F30%2FLinux%20%E5%AE%89%E8%A3%85Jenkins%2F</url>
    <content type="text"><![CDATA[安装Java(略)1234567$ java -versionjava version &quot;1.8.0_45&quot;Java(TM) SE Runtime Environment (build 1.8.0_45-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode)$ echo $JAVA_HOME ##输出Java安装目录/usr/local/jdk Ubuntu 安装jenkins1234567891011$ wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add -$ sudo sh -c &apos;echo deb http://pkg.jenkins.io/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list&apos;$ sudo apt-get update$ sudo apt-get install jenkins$ service jenkins status //jenkins服务状态$ service jenkins stop //启动jenkins$ service jenkins start //停止jenkins$ service jenkins restart //重启jenkins如果你的`/etc/init.d/jenkins`文件无法启动Jenkins，编辑`/etc/default/jenkins`， 修改 ----HTTP_PORT=8080----`为----HTTP_PORT=8081----` 在这里，“8081”也可被换为其他可用端口。ln -s /opt/jdk1.8.0_201/bin/java /usr/bin/java //创建java软连接 centos版本 安装Jenkins12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970$ sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo$ sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key$ yum install jenkinsLoaded plugins: fastestmirrorSetting up Install ProcessLoading mirror speeds from cached hostfilejenkins | 2.9 kB 00:00 jenkins/primary_db | 29 kB 00:00 Resolving Dependencies--&gt; Running transaction check---&gt; Package jenkins.noarch 0:2.176.3-1.1 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved=========================================================================================================================================================== Package Arch Version Repository Size===========================================================================================================================================================Installing: jenkins noarch 2.176.3-1.1 jenkins 74 MTransaction Summary===========================================================================================================================================================Install 1 Package(s)Total download size: 74 MInstalled size: 74 MIs this ok [y/N]: yDownloading Packages:jenkins-2.176.3-1.1.noarch.rpm | 74 MB 00:26 Running rpm_check_debugRunning Transaction TestTransaction Test SucceededRunning Transaction Installing : jenkins-2.176.3-1.1.noarch 1/1 Verifying : jenkins-2.176.3-1.1.noarch 1/1 Installed: jenkins.noarch 0:2.176.3-1.1 Complete!$ service jenkins start //启动JenkinsStarting Jenkins bash: /usr/bin/java: No such file or directory [FAILED]说明该目录下没有配置Java $ vi /etc/sysconfig/jenkins //修改一下默认端口(8080)和启动用户JENKINS_USER=&quot;root&quot;JENKINS_PORT=&quot;8081&quot;$ echo $JAVA_HOME ##输出Java安装目录/usr/local/jdk$ vim /etc/init.d/jenkins candidates=/etc/alternatives/java/usr/lib/jvm/java-1.8.0/bin/java/usr/lib/jvm/jre-1.8.0/bin/java/usr/lib/jvm/java-1.7.0/bin/java/usr/lib/jvm/jre-1.7.0/bin/java/usr/lib/jvm/java-11.0/bin/java/usr/lib/jvm/jre-11.0/bin/java/usr/lib/jvm/java-11-openjdk-amd64/usr/bin/java/usr/local/jdk/bin/java //增加Java安装目录$ service jenkins start //启动jenkins 成功Starting Jenkins [ OK ]$ cat /var/lib/jenkins/secrets/initialAdminPassword62ce0816e3c24d9aa3fac37a9a39fb4r 在浏览器输入ip:8080进入Jenkins登录页面。如图： 出现一下情况 1234解决方法： http://ip:8080/pluginManager/advanced Update Site 下的 http://updates.jenkins.io/update-center.json 修改为 https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json 之后 在浏览器输入 http://ip:8080/restart 再进入 http://ip:8080登陆即可正常$ service jenkins start //如果还不行 进行重启 如果出现登陆成功卡在空白页面 输入http://ip:8080/restart 进行重启 或 service jenkins start]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql开启log_bin并进行数据恢复]]></title>
    <url>%2F2019%2F08%2F29%2FMysql%E5%BC%80%E5%90%AFlog_bin%E5%B9%B6%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[Mysql开启binlog 日志类型 写入日志的信息 错误日志 记录在启动，运行或停止mysqld时遇到的问题 通用查询日志 记录建立的客户端连接和执行的语句 二进制日志 记录更改数据的语句 中继日志 从复制主服务器接收的数据更改 慢查询日志 记录所有执行时间超过 long_query_time 秒的所有查询或不使用索引的查询 DDL日志(元数据日志) 元数据操作由DDL语句执行 本文主要介绍二进制日志 binlog。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970Binlog日志的两个最重要的使用场景1.MySQL主从复制：MySQL Replication在Master端开启binlog，Master把它的二进制日志传递给slaves来达到master-slave数据一致的目的2.数据恢复：通过使用 mysqlbinlog工具来使恢复数据启用binlog，通过配置 /etc/my.cnf 或 /etc/mysql/mysql.conf.d/mysqld.cnf $ vim /etc/mysql/mysql.conf.d/mysqld.cnf $ service mysql restart //重启Mysql$ mysql -u root -p mysql&gt; show binary logs;1381 - You are not using binary loggingmysql&gt; show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000001 | 154 |+------------------+-----------+1 row in set (0.15 sec)mysql&gt; show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000001 | 154 |+------------------+-----------+1 row in set (0.03 sec)mysql&gt; delete from t_iost_2019_04; //开启binlog后删除数据库一张表的数据Query OK, 13244 rows affected (0.30 sec)mysql&gt; show master status; //查看目前的binlog文件+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 2006168 | dapp | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.04 sec)首先我们安装binlog2sql：$ git clone https://github.com/danfengcao/binlog2sql.git &amp;&amp; cd binlog2sql$ pip install -r requirements.txt$ cd binlog2sql$ ls -lhttotal 64Kdrwxr-xr-x 2 root root 4.0K Aug 29 17:50 binlog2sqldrwxr-xr-x 2 root root 4.0K Aug 29 17:50 example-rw-r--r-- 1 root root 35K Aug 29 17:50 LICENSE-rw-r--r-- 1 root root 9.3K Aug 29 17:50 README.md-rw-r--r-- 1 root root 54 Aug 29 17:50 requirements.txtdrwxr-xr-x 2 root root 4.0K Aug 29 17:50 tests$ pip install -r requirements.txt$ python binlog2sql/binlog2sql.py -h 127.0.0.1 -P 3306 -u admin -p&apos;admin&apos; -dtest -tuser --start-file=&apos;mysql-bin.000001&apos; --start-datetime=&apos;2019-08-26 00:00:00&apos; --stop-datetime=&apos;2019-08-26 18:00:00&apos; &gt; /tmp/raw.sql ##大致范围查找$ python binlog2sql/binlog2sql.py -h127.0.0.1 -P3306 -uadmin -p&apos;admin&apos; -dtest -tuser --start-file=&apos;mysql-bin.000054&apos; --start-position=257427 --stop-position=504272 -B &gt; /tmp/rollback.sql #找到要恢复sql的起始位置#命令解释： h 数据库ip p 数据库端口 u 账号 p 密码 d 目标库 t 表明 start-file binlog文件名 start-datetime 开始时间 stop-datetime 结束时间 &gt; 输出到指定文件 start-position 开始位置 stop-position 结束位置 B生成回滚sql$ mysql -h 127.0.0.1 -P 3306 -u admin &lt; /tmp/rollback.sql //执行回滚SQL数据的恢复mysql&gt; select count(*) from t_iost_2019_04; #查询恢复结果+----------+| count(*) |+----------+| 13244 |+----------+1 row in set (0.17 sec)]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 安装]]></title>
    <url>%2F2019%2F08%2F22%2FNginx%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Nginx下载地址 apt安装1$ apt-get install nginx 1234567891011/usr/sbin/nginx ： 主程序位置/etc/nginx：nginx文件配置/usr/share/nginx：存放静态文件/var/log/nginx：存放日志/etc/init.d/nginx start 启动Nginx/etc/init.d/nginx restart 重启Nginx 源码安装安装gcc g++的依赖库12$ apt-get install build-essential$ apt-get install libtool 复制代码安装 pcre依赖库12$ apt-get update$ apt-get install libpcre3 libpcre3-dev zlib依赖库 ssl依赖库123$ apt-get install zlib1g-dev$ apt-get install openssl 安装nginx1234567891011121314151617181920#下载最新版本：wget http://nginx.org/download/nginx-1.11.3.tar.gz#解压：tar -zxvf nginx-1.11.3.tar.gz#进入解压目录：cd nginx-1.11.3#配置：./configure --prefix=/usr/local/nginx #编辑nginx：make注意：这里可能会报错，提示“pcre.h No such file or directory”,具体详见：http://stackoverflow.com/questions/22555561/error-building-fatal-error-pcre-h-no-such-file-or-directory需要安装 libpcre3-dev,命令为：sudo apt-get install libpcre3-dev#安装nginx：sudo make install#启动nginx：sudo /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf注意：-c 指定配置文件的路径，不加的话，nginx会自动加载默认路径的配置文件，可以通过 -h查看帮助命令。#查看nginx进程：ps -ef|grep nginx 基本命令123$ ./sbin/nginx -s reload #重新加载配置$ ./sbin/nginx -s stop #停止Nginx$ /usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf #启动 配置文件详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269... #全局块events&#123; #events 块 ...&#125;http&#123; #http 块 ... #http 全局块 server&#123; #server 块 ... #server 全局块 location [PATTERN]&#123; #location 块 ... &#125; location [PATTERN]&#123; #location 块 ... &#125; &#125; server&#123; #server 块 ... &#125; ... #http 全局块&#125; 1.全局块 全局块是默认配置文件从开始到events块之间的一部分内容，主要设置一些影响Nginx服务器整体运行的配置指令，因此，这些指令的作用域是Nginx服务器全局。 通常包括配置运行Nginx 服务器的用户（组）、允许生成的worker process数、Nginx 进程 PID存放路径、日志的存放路径和类型以及配置文件引入等。 2.events 块 events 块涉及的指令主要影响Nginx 服务器与用户的网络连接。常用到的设置包括是否开启对多worker process下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型处理连接请求，每个 worker process可以同时支持的最大连接数等。 这一部分指令对 Nginx服务器的性能影响较大，在实际配置中应该根据实际情况灵活调整。 3.http 块 http块是Nginx 服务器配置中的重要部分，代理、缓存和日志定义等绝大多数的功能和第三方模块的配置都可以放在这个模块。可以在 http全局块中配置的指令包括文件引入、MIME-Type定义、日志自定义、是否使用sendfile传输文件、连接超时时间、单连接q 请求数上限等。 4.server 块 server 块和“虚拟主机”的概念有密切联系。在 server 全局块中，最常见的两个配置项是本虚拟主机的监听配置和本虚拟主机的名称或 IP 配置。 5.location 块 location 块的主要作用是，基于Nginx服务器接受到的q 请求字符串，对除虚拟主机名称之外的字符串j 进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能都是在这部分实现。许多第三方模块的配置也是在location块中提供功能。#普通配置#==性能配置#运行用户user nobody;#pid文件pid logs/nginx.pid;#Nginx基于事件的非阻塞多路复用模型（epoll或kquene）#一个进程在短时间内可以响应大量请求，工作进程设置与cpu数相同，避免cpu在多个进程间切换增加开销#==worker进程数，通常设置&lt;=CPU数量，auto为自动检测，一般设置最大8个即可，再大性能提升较小或不稳定worker_processes auto;#==将每个进程绑定到特定cpu上，避免进程在cpu间切换的开销worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;#==worker进程打开最大文件数，可CPU*10000设置，或设置系统最大数量655350worker_rlimit_nofile 102400;#全局错误日志error_log logs/error.log;#events模块中包含nginx中所有处理连接的设置，并发响应能力的关键配置events &#123; #==每个进程同时打开的最大连接数（最大并发数） worker_connections 102400; #==告诉nginx收到一个新链接通知后接受尽可能多的链接 #multi_accept on; #一般http 1.1协议下，浏览器默认使用两个并发链接 #如果是反向代理，nginx需要和客户端保持连接，还需要和后端服务器保持连接 #Http服务器时，设置max_client=worker_processes*worker_connections/2 #反向代理时，设置max_client=worker_processes*worker_connections/4 #==最大可用客户端数 #max_client #==使用非阻塞模型，设置复用客户端线程的轮训方法 use epoll;&#125;#http模块控制着nginx http处理的所有核心特性http &#123; #打开或关闭错误页面中的nginx版本号等信息 server_tokens on; #!server_tag on; #!server_info on; #==优化磁盘IO设置，指定nginx是否调用sendfile函数来输出文件，普通应用设为on，下载等磁盘IO高的应用，可设为off sendfile on; #缓存发送请求，启用如下两个配置，会在数据包达到一定大小后再发送数据 #这样会减少网络通信次数，降低阻塞概率，但也会影响响应的及时性 #比较适合于文件下载这类的大数据包通信场景 #tcp_nopush on; #tcp_nodelay on; #==设置nginx是否存储访问日志，关闭这个可以让读取磁盘IO操作更快 access_log on; #设置nginx只记录严重错误，可减少IO压力 #error_log logs/error.log crit; #Http1.1支持长连接 #降低每个链接的alive时间可在一定程度上提高响应连接数量 #==给客户端分配keep-alive链接超时时间 keepalive_timeout 30; #设置用户保存各种key的共享内存的参数，5m指的是5兆 limit_conn_zone $binary_remote_addr zone=addr:5m; #为给定的key设置最大的连接数，这里的key是addr，设定的值是100，就是说允许每一个IP地址最多同时打开100个连接 limit_conn addr 100; #include指在当前文件中包含另一个文件内容 include mime.types; #设置文件使用默认的mine-type default_type text/html; #设置默认字符集 charset UTF-8; #==设置nginx采用gzip压缩的形式发送数据，减少发送数据量，但会增加请求处理时间及CPU处理时间，需要权衡 gzip on; #==加vary给代理服务器使用，针对有的浏览器支持压缩，有个不支持，根据客户端的HTTP头来判断是否需要压缩 gzip_vary on; #nginx在压缩资源之前，先查找是否有预先gzip处理过的资源 #!gzip_static on; #为指定的客户端禁用gzip功能 gzip_disable &quot;MSIE[1-6]\.&quot;; #允许或禁止压缩基于请求和相应的响应流，any代表压缩所有请求 gzip_proxied any; #==启用压缩的最少字节数，如果请求小于1024字节则不压缩，压缩过程会消耗系统资源 gzip_min_length 1024; #==数据压缩等级，1-9之间，9最慢压缩比最大，压缩比越大对系统性能要求越高 gzip_comp_level 2; #需要压缩的数据格式 gzip_types text/plain text/css text/xml text/javascript application/json application/x-javascript application/xml application/xml+rss; #静态文件缓存 #==开启缓存的同时也指定了缓存文件的最大数量，20s如果文件没有被请求则删除缓存 open_file_cache max=100000 inactive=20s; #==多长时间检查一次缓存的有效期 open_file_cache_valid 30s; #==有效期内缓存文件最小的访问次数，只有访问超过2次的才会被缓存 open_file_cache_min_uses 2; #当搜索一个文件时是否缓存错误信息 open_file_cache_errors on; #==允许客户端请求的最大单文件字节数 client_max_body_size 4m; #==客户端请求头缓冲区大小 client_header_buffer_size 4k; #是否启用对发送给客户端的URL进行修改 proxy_redirect off; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #==nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 60; #==连接成功后，后端服务器响应时间(代理接收超时) proxy_read_timeout 120; #==后端服务器数据回传时间(代理发送超时) proxy_send_timeout 20; #==设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffer_size 32k; #==proxy_buffers缓冲区，网页平均在32k以下的设置 proxy_buffers 4 128k; #==高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 256k; #==设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 256k; #==1G内存缓冲空间，3天不用删除，最大磁盘缓冲空间2G proxy_cache_path /home/cache levels=1:2 keys_zone=cache_one:1024m inactive=3d max_size=2g; #设定负载均衡服务器列表 upstream nginx.test.com&#123; #后端服务器访问规则 #ip_hash; #weight参数表示权重值，权值越高被分配到的几率越大 #server 10.11.12.116:80 weight=5; #PC_Local server 10.11.12.116:80; #PC_Server server 10.11.12.112:80; #Notebook #server 10.11.12.106:80; &#125; #server代表虚拟主机，可以理解为站点（挂载多个站点，只需要配置多个server及upstream节点即可） server &#123; #监听80端口 listen 80; #识别的域名，定义使用nginx.test.com访问 server_name nginx.test.com; #设定本虚拟主机的访问日志 access_log logs/nginx.test.com.access.log; #一个域名下匹配多个URI的访问，使用location进行区分，后面紧跟着的/代表匹配规则 #如动态资源访问和静态资源访问会分别指向不同的位置的应用场景 # # 基本语法规则：location [=|~|~*|^~] /uri/ &#123;...&#125; # = 开头表示精确匹配 # ^~ 开头表示uri以某个常规字符串开头，匹配成功后不再进行正则匹配 # ~ 开头表示区分大小写的正则匹配 # ~* 开头表示不区分大小写的正则匹配 # !~ 开头表示区分大小写的不匹配的正则 # !~* 开头表示不区分大小写的不匹配的正则 # / 通用匹配，任何请求都会被匹配到 # # 理解如下： # 有两种匹配模式：普通字符串匹配，正则匹配 # 无开头引导字符或以=开头表示普通字符串匹配 # 以~或~*开头表示正则匹配，~*表示不区分大小写 # 【多个location时，先匹配普通字符串location，再匹配正则location】 # 只识别URI部分，例如请求为“/test/1/abc.do?arg=xxx” # （1）先查找是否有=开头的精确匹配，即“location=/test/1/abc.do &#123;...&#125;” # （2）再查找普通匹配，以“最大前缀”为规则，如有以下两个location # location /test/ &#123;...&#125; # location /test/1/ &#123;...&#125; # 则匹配后一项 # （3）匹配到一个普通location后，搜索并未结束，而是暂存当前结果，并继续进行正则搜索 # （4）在所有正则location中找到第一个匹配项后，以此匹配项为最终结果 # 【所以正则匹配项，匹配规则受定义前后顺序影响，但普通匹配不会】 # （5）如果未找到正则匹配项，则以（3）中缓存的结果为最终结果 # （6）如果一个匹配都没有，则返回404 # location =/ &#123;...&#125;与location / &#123;...&#125;的差别 # 前一个是精确匹配，只响应“/”的请求，所有“/xxx”形式的请求不会以“前缀匹配形式”匹配到它 # 后一个正相反，所有请求必然都是以“/”开头，所以没有其他匹配结果时一定会执行到它 # location ^~ / &#123;...&#125; ^~的意思是禁止正则匹配，表示匹配到此项后不再进行后续的正则搜索 # 相当于普通匹配模式匹配成功后就以此结果为最终结果，停止进行后续的正则匹配 location / &#123; #定义服务器的默认网站根目录位置，可以写相对路径，也可以写绝对路径 root html; #定义首页索引文件的名称 index index.html index.htm; #定义转发后端负载服务器组 proxy_pass http://nginx.test.com; &#125; #定义错误提示页面 error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; #静态文件，nginx自己处理 location ~ ^/(images|javascript|js|css|flash|media|static)/&#123; root /var/www/virtual/htdocs; #过期时间1天 expires 1d; #关闭媒体文件日志 access_log off; log_not_found off; &#125; #设定查看Nginx状态的地址 location /NginxStatus &#123; #!stub_status on; #无此关键字 access_log off; auth_basic &quot;NginxStatus&quot;; auth_basic_user_file conf/htpasswd; &#125; #禁止访问的文件.htxxx location ~ /\.ht &#123; #deny all;禁止访问，返回403 deny all; #allow all;允许访问 &#125; &#125; #网站较多的情况下ngxin又不会请求瓶颈可以考虑挂多个站点，并把虚拟主机配置单独放在一个文件内，引入进来 #include website.conf;&#125;]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux时区更改]]></title>
    <url>%2F2019%2F07%2F18%2FLinux%E6%97%B6%E5%8C%BA%E6%9B%B4%E6%94%B9%2F</url>
    <content type="text"><![CDATA[时区查看123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475761.tzselect命令无法修改时区，仅给出时区的城市表示法2.TZ变量和/etc/localtime文件会影响时区，并建议直接修改/etc/localtime文件3.如果在shell中临时需要变更时区信息，可以修改TZ变量实现。4.在profile文件里设置变量TZ，达到和修改/etc/localtime类似的效果。$ tzselectPlease identify a location so that time zone rules can be set correctly.Please select a continent, ocean, &quot;coord&quot;, or &quot;TZ&quot;. 1) Africa 2) Americas 3) Antarctica 4) Asia 5) Atlantic Ocean 6) Australia 7) Europe 8) Indian Ocean 9) Pacific Ocean10) coord - I want to use geographical coordinates.11) TZ - I want to specify the time zone using the Posix TZ format.#? 4Please select a country whose clocks agree with yours. 1) Afghanistan 18) Israel 35) Palestine 2) Armenia 19) Japan 36) Philippines 3) Azerbaijan 20) Jordan 37) Qatar 4) Bahrain 21) Kazakhstan 38) Russia 5) Bangladesh 22) Korea (North) 39) Saudi Arabia 6) Bhutan 23) Korea (South) 40) Singapore 7) Brunei 24) Kuwait 41) Sri Lanka 8) Cambodia 25) Kyrgyzstan 42) Syria 9) China 26) Laos 43) Taiwan10) Cyprus 27) Lebanon 44) Tajikistan11) East Timor 28) Macau 45) Thailand12) Georgia 29) Malaysia 46) Turkmenistan13) Hong Kong 30) Mongolia 47) United Arab Emirates14) India 31) Myanmar (Burma) 48) Uzbekistan15) Indonesia 32) Nepal 49) Vietnam16) Iran 33) Oman 50) Yemen17) Iraq 34) Pakistan#? 9Please select one of the following time zone regions.1) Beijing Time2) Xinjiang Time#? 1The following information has been given: China Beijing TimeTherefore TZ=&apos;Asia/Shanghai&apos; will be used.Local time is now: Thu Jul 18 15:54:50 CST 2019.Universal Time is now: Thu Jul 18 07:54:50 UTC 2019.Is the above information OK?1) Yes2) No#? yesPlease enter a number in range.#? yesPlease enter a number in range.#? 1You can make this change permanent for yourself by appending the line TZ=&apos;Asia/Shanghai&apos;; export TZto the file &apos;.profile&apos; in your home directory; then log out and log in again.Here is that TZ value again, this time on standard output so that youcan use the /usr/bin/tzselect command in shell scripts:Asia/Shanghaicurl http://ifconfig.me 12345678910111213141516171819202122232425262728293031323334353637$ cat /etc/profile //在文件末尾追加时区 export TZ=Asia/Shanghai # /etc/profile: system-wide .profile file for the Bourne shell (sh(1))# and Bourne compatible shells (bash(1), ksh(1), ash(1), ...).if [ &quot;$PS1&quot; ]; then if [ &quot;$BASH&quot; ] &amp;&amp; [ &quot;$BASH&quot; != &quot;/bin/sh&quot; ]; then # The file bash.bashrc already sets the default PS1. # PS1=&apos;\h:\w\$ &apos; if [ -f /etc/bash.bashrc ]; then . /etc/bash.bashrc fi else if [ &quot;`id -u`&quot; -eq 0 ]; then PS1=&apos;# &apos; else PS1=&apos;$ &apos; fi fifiif [ -d /etc/profile.d ]; then for i in /etc/profile.d/*.sh; do if [ -r $i ]; then . $i fi done unset ifiexport JAVA_HOME=/usr/local/java/jdk1.8.0_211export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib:$CLASSPATHexport JAVA_PATH=$&#123;JAVA_HOME&#125;/bin:$&#123;JRE_HOME&#125;/binexport PATH=$PATH:$&#123;JAVA_PATH&#125;export TZ=Asia/Shanghai $ source /etc/profile //生效文件]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建简单的文件下载服务器]]></title>
    <url>%2F2019%2F06%2F18%2F%E6%90%AD%E5%BB%BA%E7%AE%80%E5%8D%95%E7%9A%84%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[[apache2]123456789$ root@user: apt-getinstall apache2 //配置文件地址 /etc/apache2/sites-enabled/000-default$ root@user: cd /var/www/html/ //并在此目录放入要下载的文件$ root@user: rm -f index.html //删除该文件$ root@user: curl cip.cc //获取服务器外网IP 通过浏览器访问 如图 $ root@user: /etc/init.d/apache2 restart //重启Apache2 $ root@user: /etc/init.d/apache2 stop //停止Apache2 [Nginx]12345678910111213141516171819202122232425262728293031323334353637$ root@user: apt-getinstall nginx //配置文件地址 /etc/nginx/nginx.conf 在nginx.conf末尾有一句：include /etc/nginx/conf.d/*.conf; 推荐把用户自己的配置放到conf.d/$ root@user: vim /etc/nginx/conf.d/default.conf //添加用户的自定义配置文件 autoindex on;# 显示目录 autoindex_exact_size on;# 显示文件大小 autoindex_localtime on;# 显示文件时间$ root@user: vim /etc/nginx/nginx.conf //在http 增加以下配置 server &#123; listen 8080 default_server; listen [::]:8080 default_server; server_name _; root /root/share/; //分项目录 # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125; &#125;$ root@user: /etc/init.d/nginx reload 重新加载$ root@user: curl cip.cc //获取服务器外网IP 通过浏览器访问 如图 错误日志 /var/log/nginx/error.log访问日志 /var/log/nginx/access.log]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql 安装]]></title>
    <url>%2F2019%2F06%2F14%2FMysql%20%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243//下载mysql-apt-config_0.8.13-1_all.deb 到Linux $apt-get update $mkdir mysql$cd mysql//安装$apt-get install mysql-server//查看Mysql服务状态$ service mysql status//重启Mysql$service mysql restart//查看Mysql端口占用$netstat -tunlp | grep 3306//进行安装初始化设置密码等操作$ mysql_secure_installation//设置 Linux服务器数据库可以在任意服务器上远程连接$ mysql -u root -p mysql&gt; show databases;mysql&gt; use mysql;mysql&gt; select host, user from user;mysql&gt; update user set host = &apos;%&apos; where user = &apos;root&apos;;mysql&gt; flush privileges;mysql&gt; exit;从命令行终端运行此命令，将在寻找Linux/BSD / OS X系统中的MySQL配置文件 my.cnf 文件：mysql --help | grep &apos;Default options&apos; -A 1上面命令执行后，会有这样的输出：Default options are read from the following files in the given order:/etc/my.cnf /etc/mysql/my.cnf /usr/local/etc/my.cnf ~/.my.cnf现在，可以检查你正在使用的 my.cnf 文件是否存在。在 Mac OS X 中默认式没有 my.cnf 文件的。你可以从这个地方复制一份过去 /usr/local/mysql/support-files/my-default.cnf 每个版本都不一样，你只需要找到一个 .cnf]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 系统搭建Redis]]></title>
    <url>%2F2019%2F06%2F13%2FLinux%20%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BARedis%2F</url>
    <content type="text"><![CDATA[Installation1234567891011121314151617181920212223$ mkdir redis //创建redis目录$ wget http://download.redis.io/releases/redis-5.0.5.tar.gz //下载安装包$ tar xzf redis-5.0.5.tar.gz //解压 $ cd redis-5.0.5 //进入redis-5.0.5目录 $ make //生成有效文件$ cd src $ ./redis-server //1.启动redis服务 这种方式启动redis 使用的是默认配置$ ./redis-cliredis&gt; set foo barOKredis&gt; get foo&quot;bar&quot;$ vim ../redis.conf //编辑Redis配置文件$ ./redis-server ../redis.conf //2.使用指定配置文件使用下面命令启动 redis 配置文件详解 fields desc daemonize no 默认情况下，redis不是在后台运行的，如果需要在后台运行，把该项的值更改为yes port 指定redis运行的端口，默认是6379 bind 指定redis只接收来自于该IP地址的请求，如果不进行设置，那么将处理所有请求，在生产环境中最好设置该项 timeout 设置客户端连接时的超时时间，单位为秒。当客户端在这段时间内没有发出任何指令，那么关闭该连接 0是关闭此设置 loglevel # debu 记录很多信息，用于开发和测试 varbose 有用的信息，不像debug会记录那么多 notice 普通的verbose，常用于生产环境 warning 只有非常重要或者严重的信息会记录到日志 logfile /var/log/redis/redis.log 配置log文件地址 默认值为stdout，标准输出，若后台模式会输出到/dev/null rdbcompression yes 存储至本地数据库时（持久化到rdb文件）是否压缩数据，默认为yes dbfilename dump.rdb 本地持久化数据库文件名，默认值为dump.rdb requirepass foobared 设置客户端连接后进行任何其他指定前需要使用的密码。 save 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 save 900 1 900秒（15分钟）内有1个更改 windows Redis Desktop Manager 连接不上Redis的问题1231. ufw status 查看Redis 6379 端口是否开启 未开启则 ：ufw allow 6379(Redis默认端口 修改默认端口到redis.conf修改)2. 云平台安全组是否开启了Redis 6379 端口]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见问题汇总]]></title>
    <url>%2F2019%2F06%2F13%2F%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[Linuxcmmand redis-cli not found123456789root@wrecked:~# redis-cli -h 127.0.0.1 -p 6379 -a 123456Command &apos;redis-cli&apos; not found解决办法：cp /home/redis/redis-2.8.17/src/redis-cli /usr/local/bin/ 拷贝redis-cli 到 /usr/local/bin/ `/usr/bin`下面的都是系统预装的可执行程序，会随着系统升级而改变。`/usr/local/bin`目录是给用户放置自己的可执行程序的地方，推荐放在这里，不会被系统升级而覆盖同名文件。 buntu防火墙的开启，关闭，端口的打开，查看1234567891011121314151.防火墙的打开$ ufw enable2.防火墙的重启$ ufw reload3.打开想要的端口（以9000为例）$ ufw allow 90004.查看本机端口使用情况$ ufw status]]></content>
      <categories>
        <category>问题</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统配置]]></title>
    <url>%2F2019%2F06%2F11%2FLinux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[基础概念 物理CPU：物理CPU就是插在主机上的真实的CPU硬件，在Linux下可以数不同的physical id 来确认主机的物理CPU个数。 核心数：物理CPU下一层概念就是核心数，我们常常会听说多核处理器，其中的核指的就是核心数。在Linux下可以通过cores来确认主机的物理CPU的核心数。 逻辑CPU：核心数下一层的概念是逻辑CPU，逻辑CPU跟超线程技术有联系，假如物理CPU不支持超线程的，那么逻辑CPU的数量等于核心数的数量； 如果物理CPU支持超线程，那么逻辑CPU的数目是核心数数目的两倍。在Linux下可以通过 processors 的数目来确认逻辑CPU的数量。 超线程：超线程是英特尔开发出来的一项技术，使得单个处理器可以象两个逻辑处理器那样运行，这样单个处理器以并行执行线程。 这里的单个处理器也可以理解为CPU的一个核心；这样便可以理解为什么开启了超线程技术后，逻辑CPU的数目是核心数的两倍了。 查看物理CPU数量1cat /proc/cpuinfo | grep &apos;physical id&apos; | uniq |wc -l 查看核心数1cat /proc/cpuinfo | grep &apos;core id&apos; | uniq |wc -l 查看逻辑CPU数目123top命令中看到的CPU数目是逻辑CPU（输入top后再按1）。cat /proc/cpuinfo | grep &apos;processor&apos; | wc -l 查看内存大小 硬盘大小12cat /proc/meminfo |grep MemTotal //内存大小fdisk -l |grep Disk //硬盘大小]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客基本配置]]></title>
    <url>%2F2019%2F06%2F04%2F%E5%8D%9A%E5%AE%A2%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[环境初始化1234567891011121314151617npm install hexo-cli -g //安装hexo modulesmkdir WreckedBolg //创建目录 cd WreckedBolg //进入目录 hexo init //初始化目录npm install hexo-deployer-git --save 安装部署gitHub依赖git clone https://github.com/theme-next/hexo-theme-next themes/next //主题文件地址npm install hexo-generator-searchdb --save //搜素引擎依赖包 npm install hexo-related-popular-posts --save //相关文章包 Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server //生成本地Service http://localhost:4000/ 访问地址 hexo s 简写 More info: Server Generate static files1$ hexo generate //生成静态HTML hexo g 简写 More info: Generating Deploy to remote sites1$ hexo deploy //部署到GitHub hexo d 简写 More info: Deployment 配置文件 _config.yml1234deploy: type: git repo: https://github.com/***/***.github.io.git branch: master 常用命令1234567891011hexo g #完整命令为hexo generate,用于生成静态文件hexo s #完整命令为hexo server,用于启动服务器，主要用来本地预览hexo d #完整命令为hexo deploy,用于将本地文件发布到github等git仓库上hexo n “my article” #完整命令为hexo new,用于新建一篇名为“my article”的文章hexo n “我的第一篇文章”hexo list page / post / route / tag / category(参数) 查看博客对应信息 背景图设置123..\themes\next\layout\_layout.swig 目录 找到&lt;Body&gt;标签 设置背景图片 style=&quot;background: url(https://raw.githubusercontent.com/zhangChaoWrecked/pictures/master/Background.jpg) no-repeat fixed ;&quot; 点击跳转配置教程链接]]></content>
  </entry>
  <entry>
    <title><![CDATA[如何在一台电脑使用GitHub GitLab进行项目维护]]></title>
    <url>%2F2019%2F06%2F04%2F%E5%A6%82%E4%BD%95%E5%9C%A8%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91%E4%BD%BF%E7%94%A8GitHub%20GitLab%E8%BF%9B%E8%A1%8C%E9%A1%B9%E7%9B%AE%E7%BB%B4%E6%8A%A4%2F</url>
    <content type="text"><![CDATA[1.生成SSH Key123在 C:\Users\用户名\.ssh 目录 鼠标右键 git bash ssh-keygen -t rsa -C &quot;****@qq.com&quot; //生成pub文件需指定生成文件名 id_rsa_hub/id_rsa_lab 区分GitHub/GitLabssh-keygen -t rsa -C &quot;****@163.com&quot; 2.配置Config123456789101112131415161718192021222324252627282930在 C:\Users\用户名\.ssh 目录 生成config文件 编辑如下：# self(****@qq.com)Host github(拉取代码时仓库的别名) Port 22 User git HostName github.com (github域名) PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa_hub (生成的GitHub公钥)# company(****@163.com)Host gitlab(拉取代码时仓库的别名) Port 端口(默认22) User git HostName ******* (公司GitLab域名) PreferredAuthentications publickey IdentityFile ~/.ssh/id_rsa_lab(生成的GitLab公钥) Host 作用[github为例]：#传统使用$git clone git@github.com:zhangChaoWrecked/pictures.git$git remote add origin git@github.com:zhangChaoWrecked/pictures.git#配置Config之后使用(host也可配置为域名即:github.com) $git clone git@[Host]:zhangChaoWrecked/pictures.git$git remote add origin git@[Host]:zhangChaoWrecked/pictures.git 生成文件如下图： 配置Hosts 加速 拉取代码速度12151.101.185.194 github.global.ssl.fastly.net192.30.253.112 github.com 3.测试关联12ssh -T git@githubssh -T git@gitlab 4.拉取远程代码或下载到本地12345678910#取消全局 用户名/邮箱 配置(可跳过)$git config --global --unset user.name$git config --global --unset user.email$cd 项目名$git init$git config --local user.name &quot;用户名&quot;$git config --local user.email &quot;邮箱&quot;$git remote add origin git@[host]:***/***.git(git remote rm origin 删除之前关联的origin)$git pull orgin master]]></content>
      <tags>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Volatile]]></title>
    <url>%2F2019%2F02%2F22%2FVolatile%2F</url>
    <content type="text"><![CDATA[上下文切换 阐述：CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换 如何减少上下文切换 方案 无锁并发编程 将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据 CAS算法 Java的Atomic包使用CAS算法来更新数据，而不需要加锁 使用最少线程 避免创建不需要的线程 volatile 描述 特点 1.使用volatile关键字会强制将修改的值立即写入主存 1.保证有序性、可见性 2.导致其他线程的工作内存中缓存变量的缓存行无效 2.不保证原子性 1应用场景：状态标志]]></content>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ安装]]></title>
    <url>%2F2019%2F01%2F19%2FRabbitMQ%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[erlang下载 rabbit下载 cmd命令行12345&quot;E:\rabbitMq\rabbitmq_server-3.7.10\sbin\rabbitmq-plugins.bat&quot; enable rabbitmq_management 开启web管理接口 net stop RabbitMQ &amp;&amp; net start RabbitMQ 重启rabbitMQrabbitmqctl.bat list_users 列出当前用户列表 账号 密码 guest(默认) guest(默认) 本地浏览器打开]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>rabbitmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java DES(对称加密)]]></title>
    <url>%2F2019%2F01%2F16%2FJava%20Crypto(%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86)%2F</url>
    <content type="text"><![CDATA[简单一种对称加密与解密123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104import javax.crypto.Cipher;import javax.crypto.KeyGenerator;import javax.crypto.SecretKey;import javax.crypto.spec.SecretKeySpec;public class DESUtils &#123; /* * 生成密钥 */ public static byte[] initKey() throws Exception &#123; KeyGenerator keyGen = KeyGenerator.getInstance("DES"); keyGen.init(56); SecretKey secretKey = keyGen.generateKey(); return secretKey.getEncoded(); &#125; /* * DES 加密 */ public static String encrypt(byte[] data, byte[] key) throws Exception &#123; SecretKey secretKey = new SecretKeySpec(key, "DES"); Cipher cipher = Cipher.getInstance("DES"); cipher.init(Cipher.ENCRYPT_MODE, secretKey); byte[] cipherBytes = cipher.doFinal(data); String result = byte2Hex(cipherBytes); return result; &#125; /* * DES 解密 */ public static String decrypt(byte[] data, byte[] key) throws Exception &#123; SecretKey secretKey = new SecretKeySpec(key, "DES"); Cipher cipher = Cipher.getInstance("DES"); cipher.init(Cipher.DECRYPT_MODE, secretKey); byte[] plainBytes = cipher.doFinal(data); String result = new String(plainBytes); return result; &#125; private static int toByte(char c) &#123; byte b = (byte) "0123456789ABCDEF".indexOf(c); return b; &#125; public static byte[] hexToByte(String hex) &#123; int len = (hex.length() / 2); byte[] result = new byte[len]; char[] achar = hex.toCharArray(); for (int i = 0; i &lt; len; i++) &#123; int pos = i * 2; result[i] = (byte) (toByte(achar[pos]) &lt;&lt; 4 | toByte(achar[pos + 1])); &#125; return result; &#125; public static String byte2Hex(byte[] b) &#123; String stmp = ""; StringBuilder sb = new StringBuilder(""); for (int n = 0; n &lt; b.length; n++) &#123; stmp = Integer.toHexString(b[n] &amp; 0xFF); sb.append((stmp.length() == 1) ? "0" + stmp : stmp); &#125; return sb.toString().toUpperCase().trim(); &#125; //加密 public static String encryptStr(String str, String secreytKey) throws Exception &#123; String enResult = encrypt(str.getBytes(), hexToByte(secreytKey)); return enResult; &#125; //解密 public static String decryptStr(String str, String secreytKey) throws Exception &#123; String deResult = decrypt(hexToByte(str), hexToByte(secreytKey)); return deResult; &#125; /*** * 秘钥769bfbae9d20100d 加密结果e3f6b60180661bb0d541de00260afb10 解密结果hello_world * * @param args * @throws Exception */ public static void main(String[] args) throws Exception &#123; //生成秘钥 byte[] desKey = initKey(); String secreytKey = byte2Hex(desKey); System.out.println("秘钥" + secreytKey.toLowerCase()); //加密 String hello_world = encryptStr("hello_world", secreytKey); System.out.println("加密结果" + hello_world.toLowerCase()); //解密 String deResult = decryptStr(hello_world, secreytKey); System.out.println("解密结果" + deResult); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Crypto</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal]]></title>
    <url>%2F2018%2F12%2F04%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[ThreadLocal 类结构图 get12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; set12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; remove12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125; setInitialValue12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value; &#125; initialValue123protected T initialValue() &#123; return null;&#125; getMap123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; createMap123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue); &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux Top命令]]></title>
    <url>%2F2018%2F11%2F30%2FLinux%20Top%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[uptime / top116:36:50 up 108 days, 7:24, 2 users, load average: 61.27, 61.50, 61.60 Field Desc 16:36:50 时间 up 1:22 系统运行时间 users 当前登录用户数 load average 三个数值分别为 1分钟、5分钟、15分钟前到现在的平均负载 英文文档链接 Understanding-Load-Averages中文文档链接 Understanding-Load-AveragesTasks key value Desc 29 total 进程总数 1 running 正在运行的进程数 28 sleeping 睡眠的进程数 0 stopped 停止的进程数 0 zombie 僵尸进程数 Cpu(s) key value Desc 0.3% us 用户空间占用CPU百分比 1.0% sy 内核空间占用CPU百分比 0.0% ni 用户进程空间内改变过优先级的进程占用CPU百分比 98.7% id 空闲CPU百分比 0.0% wa 等待输入输出的CPU时间百分比 Mem key value Desc 191272k total 物理内存总量 173656k used 使用的物理内存总量 17616k free 空闲内存总量 22052k buffers 用作内核缓存的内存量 Swap key value Desc 192772k total 交换区总量 0k used 使用的交换区总量 192772k free 空闲交换区总量 123988k cached 缓冲的交换区总量。 详细信息 Key Desc PID 进程id PPID 父进程id RUSER Real user name UID 进程所有者的用户id USER 进程所有者的用户名 GROUP 进程所有者的组名 TTY 启动进程的终端名。不是从终端启动的进程则显示为 ? PR 优先级 NI nice值。负值表示高优先级，正值表示低优先级 P 最后使用的CPU，仅在多CPU环境下有意义 %CPU 上次更新到现在的CPU时间占用百分比 TIME 进程使用的CPU时间总计，单位秒 TIME+ 进程使用的CPU时间总计，单位1/100秒 %MEM 进程使用的物理内存百分比 VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。 RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA CODE 可执行代码占用的物理内存大小，单位kb DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb SHR 共享内存大小，单位kb nFLT 页面错误次数 nDRT 最后一次写入到现在，被修改过的页面数。 S 进程状态。 S D=不可中断的睡眠状态 S R=运行 S S=睡眠 S T=跟踪/停止 S Z=僵尸进程 COMMAND 命令名/命令行 WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名 Flags 任务标志，参考 sched.h]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis Info命令详解]]></title>
    <url>%2F2018%2F11%2F29%2FRedis%20Info%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Redis 内存使用率Memory1info memory //Redis命令 Field Value Description used_memory 3228479928 used_memory_human 3.01G redis已经使用内存 used_memory_rss 5631479808 used_memory_rss_human 5.24G 从操作系统的角度，返回 Redis 已分配的内存总量(俗称常驻集大小) used_memory_peak 10753524688 used_memory_peak_human 10.02G 曾经占用内存的峰值 used_memory_peak_perc 30.02% (used_memory/ used_memory_peak) *100% used_memory_overhead 207532802 Redis为了维护数据集的内部机制所需的内存开销 used_memory_startup 6144240 Redis服务器启动时消耗的内存 used_memory_dataset 3020947126 used_memory—used_memory_overhead used_memory_dataset_perc 93.75% 100%*(used_memory_dataset/(used_memory—used_memory_startup)) total_system_memory 33738252288 total_system_memory_human 31.42G 服务器本身的内存大小 used_memory_lua 51200 used_memory_lua_human 50.00K Lua 引擎所使用的内存大小 maxmemory 10737418240 maxmemory_human 10.00G 服务器设定的redis可以使用的最大内存 maxmemory_policy noeviction 当达到maxmemory时的淘汰策略 mem_fragmentation_ratio 1.74 碎片率意味着74%的内存浪费 mem_allocator jemalloc-4.0.3 内存分配器 active_defrag_running 0 lazyfree_pending_objects 0 maxmemory_policy 选择策略 Fields Description noeviction 默认策略，不淘汰，如果内存已满，添加数据是报错。 allkeys-lru 在所有键中，选取最近最少使用的数据抛弃。 volatile-lru 在设置了过期时间的所有键中，选取最近最少使用的数据抛弃。 allkeys-random 在所有键中，随机抛弃 volatile-random 在设置了过期时间的所有键，随机抛弃 volatile-ttl 在设置了过期时间的所有键，抛弃存活时间最短的数据 Server1info server //Redis 命令 Fiels Value Description redis_version 4.0.9 Redis 服务器版本 redis_git_sha1 00000000 redis_git_dirty 0 redis_build_id 1981f57149260a90 redis_mode standalone 运行模式，单机或者集群 os Linux 4.4.0-105-generic x86_64 Redis 服务器的宿主操作系统 arch_bits 64 架构（32 或 64 位） multiplexing_api epoll Redis 所使用的事件处理机制 atomicvar_api atomic-builtin 原子处理api gcc_version 5.4.0 编译 Redis 时所使用的 GCC 版本 process_id 8004 服务器进程的 PID run_id 6a5182bea61558be39d072ab5fd14579f12fc271 Redis 服务器的随机标识符（用于 Sentinel 和集群） tcp_port 6379 监听端口 uptime_in_seconds 1406431 自 Redis 服务器启动以来，经过的秒数 uptime_in_days 16 自 Redis 服务器启动以来，经过的天数 hz 10 lru_clock 16752391 以分钟为单位进行自增的时钟，用于 LRU 管理 executable /home/lianxiang/redis/redis-4.0.9/src/redis-server 执行文件地址 config_file /home/redis/redis.conf 配置文件地址 Clients1info clients //Redis 命令 Fiels Value Description connected_clients 11721 已连接客户端的数量（不包括通过从属服务器连接的客户端） client_longest_output_list 0 当前连接的客户端当中，最长的输出列表 client_biggest_input_buf 18 当前连接的客户端当中，最大输入缓存 blocked_clients 0 正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量 Commandstats1info commandstats //Redis 命令 Fiels Value Description cmdstat_cluster calls=77,usec=117,usec_per_call=1.52 使用次数/总时间(微秒数)/平均时间 cmdstat_zremrangebyscore calls=402280989,usec=3007286205,usec_per_call=7.48 … cmdstat_script calls=31,usec=533,usec_per_call=17.19 … cmdstat_evalsha calls=58716,usec=7416675,usec_per_call=126.31 … cmdstat_smembers calls=1031965,usec=25706632,usec_per_call=24.91 … cmdstat_sscan calls=15,usec=1026,usec_per_call=68.40 … cmdstat_hkeys calls=294,usec=211364,usec_per_call=718.93 … cmdstat_expire calls=124221201,usec=292783944,usec_per_call=2.36 … cmdstat_zrangebyscore calls=37214253,usec=358725386,usec_per_call=9.64 … cmdstat_hmget calls=7,usec=38,usec_per_call=5.43 … cmdstat_zrevrange calls=9772,usec=98592,usec_per_call=10.09 … cmdstat_hget calls=21564966,usec=41137042,usec_per_call=1.91 … cmdstat_scan calls=47381,usec=26088568,usec_per_call=550.61 … … … … 慢查询日志1SlowLog Get 1 //获取一条 1SlowLog Len //慢日志数量 Fiels Value Description 1) “67227” 唯一性(unique)的日志标识符 2) “1543481885” 被记录命令的执行时间点，以 UNIX 时间戳格式表示 3) “10104” 查询执行时间，以微秒为单位 4.1) “ZADD” 执行的命令 4.2) PAIR_MARKET_DEPTH_SELL:4:3115” 完整的命令 4.3) “0.02638215” 参数 4.4) “[0.026382150000000000,101.470000000000000000]” 参数 4.5) “47.91.198.244:43484” IP+端口]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 常用命令]]></title>
    <url>%2F2018%2F11%2F29%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux 命令远程连接Linux服务器1$ ssh -i [.pem文件] [用户名]@[外网IP] 查看公网IP123$ curl cip.cc$ curl http://ifconfig.me grep(查询 筛选)1-A,-B,-C //分别可以显示匹配行的后,前,后前多少行内容 1&apos;2016-04-13 11:26:00&apos; //关键词,注意是单引号包裹 1$ catalina.out //检索的文件 可以是目录 1$ more // 以分页的形式 1$ grep -C 10 &apos;连接池异常&apos; catalina.out //查找某字段的前后多少行 1$ tail -500f catalina.out |grep &apos;连接池异常&apos; //查询tomcat 末尾指定行数的过滤日志 find(查找文件)1234567$ find / -name *sync-huobi*$ $ find / -name filename.txt //根据名称查找/目录下的filename.txt文件。$ $ find . -name &quot;*.xml&quot; //递归查找所有的xml文件$ $ find . -name &quot;*&quot; |xargs grep &quot;hello&quot; //递归查找所有文件内容中包含hello world的xml文件 grep(搜索)1234567891011$ grep -H &apos;spring&apos; *.xml //查找所以有的包含spring的xml文件$ $ find ./ -size 0 | xargs rm -f &amp; //删除文件大小为零的文件$ $ ls -l | grep &apos;.jar&apos; //查找当前目录中的所有jar文件$ $ grep &apos;test&apos; d* //显示所有以d开头的文件中包含test的行$ $ grep &apos;test&apos; aa bb cc //显示在aa，bb，cc文件中匹配test的行$ $ grep &apos;[a-z]\&#123;5\&#125;&apos; aa //显示所有包含每个字符串至少有5个连续小写字符的字符串的行 ps (查看一个程序是否运行)12345$ ps –ef|grep tomcat //查看所有有关tomcat的进程$ $ ps -ef|grep --color java //高亮要查询的关键字$ $ kill -9 19979 //终止线程号位19979的进程 ls (查看文件，包含隐藏文件)1234567$ ls -al //当前工作目录$ $ pwd //复制文件$ $ cp source dest //复制文件$ $ cp -r sourceFolder targetFolder //递归复制整个文件夹 mkdir (创建目录件)123456789$ mkdir newfolder //删除目录$ $ rmdir deleteEmptyFolder //删除空目录 $ $ rm -rf deleteFile //递归删除目录中所有内容$ $ mv /temp/movefile /targetFolder //移动文件$ $ mv oldNameFile newNameFile //重命名 切换用户123$ su -username$ $ sudo rm a.txt 使用管理员身份删除文件 修改文件/用户权限1234567$ chmod 777 file.java file.java的权限-rwxrwxrwx，r表示读、w表示写、x表示可执行$ $ chmod 777 xxx.sh //赋予脚本执行权$ $ sudo chown -R ubuntu /home/ubuntu //给某用户增加该目录权限$ $ touch xxx.sh //创建文件 压缩文件12345678910111213141516$ tar -czf test.tar.gz /test1 /test2 //列出压缩文件列表$ $ tar -tzf test.tar.gz //解压文件$ $ tar -xvzf test.tar.gz //解压文件$ $ head -n 10 example.txt //查看文件前10行$ $ tail -n 10 example.txt //查看文件后10行 $ $ tail -f exmaple.log //查看日志最近更新$ $ netstat -tln | grep 8080 查看端口8080的使用情况 //查看端口占用情况$ $ lsof -i :8080 //查看端口属于哪个进程 ps(查看进程)1234567891011$ ps aux|grep java //查看java进程$ $ ps aux //查看所有进程$ $ tree a //以树状格式列出目录$ $ wget http://file.tgz //文件下载$ $ curl http://file.tgz //请求URL$ $ ping www.just-ping.com //网络检测 Redis (查看大Key)1$ redis-cli -h IP -p 6379 -a password --bigkeys 启动SpringBoot Jar12345$ nohup java -jar exchange-announcement-0.0.1-SNAPSHOT.jar &amp; //后台启动一个Jar包$ $ tail -500f nohup.out //查看日志$ $ ps -ef|grep exchange-announcement-0.0.1-SNAPSHOT.jar //查看进程ID]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Redis</tag>
        <tag>SpingBoot</tag>
      </tags>
  </entry>
</search>
